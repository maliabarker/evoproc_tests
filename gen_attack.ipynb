{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e350c961",
   "metadata": {},
   "source": [
    "# ðŸ§¡ Generating Generalization Attacks for **EvoProc** procedures for the **GSM8K Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286fbf7b",
   "metadata": {},
   "source": [
    "Pseduo-code Plan\n",
    "\n",
    "Note: Dataset is only the first 275 questions of the GSM8K dataset training batch (accessed with HuggingFace `dataset` library)\n",
    "1. For each question in the dataset\n",
    "    \n",
    "    a. Change the numbers in the question\n",
    "\n",
    "    b. Using the new numbers, calculate the new \"golden number\" (aka the final answer)\n",
    "\n",
    "    c. Ensure that the final answer is an INTEGER (common practice in the GSM8K dataset)\n",
    "\n",
    "2. For each new mutated question (question with new numbers)\n",
    "\n",
    "    a. Proc Answer: Use the corresponding procedure from the file `/home/student/Desktop/malia/evoproc_tests/runs/gsm8k_train_v6.jsonl` (access the procedure using `instance[\"procedure\"]`). Run each step with the NEW problem text inserted.\n",
    "\n",
    "    b. Baseline answer: Pass NEW problem text\n",
    "\n",
    "3. Compare % decrease in accuracy for both proc and baseline answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ad3473",
   "metadata": {},
   "source": [
    "## ðŸŸ§ **Step 1**: Import packages and necessary application functions & variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08cc3cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/Desktop/malia/evoproc_tests/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import traceback\n",
    "import pandas as pd\n",
    "from hashlib import blake2b\n",
    "from datetime import datetime, timezone\n",
    "from datasets import load_dataset\n",
    "from typing import Callable, Optional, Dict, Any, Tuple\n",
    "from evoproc.ga_scaffold_structured import ProcedureGA, GAConfig\n",
    "from evoproc.validators import validate_procedure_structured\n",
    "from evoproc_procedures.schemas import get_schema\n",
    "from evoproc_procedures.prompts import create_procedure_prompt\n",
    "from evoproc_procedures.ollama import query, repair_fn_ollama\n",
    "from evoproc_procedures.runners import run_steps_stateful_minimal\n",
    "from evoproc_procedures.helpers import pretty_print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afda795",
   "metadata": {},
   "source": [
    "## ðŸŸ§ **Step 2**: Import the GSM8K Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661e6381",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm8k_dataset = load_dataset(\"gsm8k\", \"main\", split=\"train[:275]\")\n",
    "# Use the first 275 questions as requested\n",
    "subsample = gsm8k_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŸ§ **Step 2b**: Load prior procedures and set up mutation/solver helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to existing results (procedures)\n",
    "PROC_RESULTS_PATH = \"runs/gsm8k_train_v6.jsonl\"\n",
    "BASELINE_RESULTS_PATH = \"runs/gsm8k_train_v6_baseline.jsonl\"\n",
    "\n",
    "# New output files for the generalization attack\n",
    "GENERALIZATION_PROC_OUT = \"runs/generalization_attack_results.jsonl\"\n",
    "GENERALIZATION_BASELINE_OUT = \"runs/generalization_attack_baseline_results.jsonl\"\n",
    "\n",
    "def _read_jsonl_allowing_comments(path):\n",
    "    records = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"//\"):\n",
    "                continue\n",
    "            records.append(json.loads(line))\n",
    "    return records\n",
    "\n",
    "proc_records = _read_jsonl_allowing_comments(PROC_RESULTS_PATH)\n",
    "procedures_by_row = {rec.get(\"row_index\"): rec.get(\"procedure\") for rec in proc_records if rec.get(\"procedure\") is not None}\n",
    "\n",
    "# Reasoning extraction: take everything before the final #### line\n",
    "def extract_reasoning(answer_text: str) -> str:\n",
    "    if not answer_text:\n",
    "        return \"\"\n",
    "    parts = answer_text.split(\"####\")\n",
    "    return parts[0].strip()\n",
    "\n",
    "_NUM_RE = re.compile(r\"-?\\d+\")\n",
    "\n",
    "# Mutate numbers in a question while keeping mapping (by value)\n",
    "def mutate_numbers_in_text(text: str, rng: random.Random, min_val: int = 1, max_val: int = 99):\n",
    "    mapping = {}\n",
    "    def repl(m):\n",
    "        s = m.group(0)\n",
    "        if s not in mapping:\n",
    "            orig = int(s)\n",
    "            new = orig\n",
    "            for _ in range(50):\n",
    "                new = rng.randint(min_val, max_val)\n",
    "                if new != orig:\n",
    "                    break\n",
    "            mapping[s] = new\n",
    "        return str(mapping[s])\n",
    "    new_text = _NUM_RE.sub(repl, text)\n",
    "    return new_text, mapping\n",
    "\n",
    "# Solver to create new gold answers using original reasoning as a template\n",
    "def solve_gold_with_reasoning(question: str, reasoning: str, query_fn, model: str, seed: int = 1234, max_retries: int = 3):\n",
    "    base_prompt = (\n",
    "        \"Solve the GSM8K problem with the new numbers.\\n\"\n",
    "        \"You are given the original reasoning path as a template.\\n\"\n",
    "        \"Recompute all arithmetic with the NEW numbers; do not copy old numeric results.\\n\"\n",
    "        \"Return ONLY JSON with keys: \\\"final_answer\\\" (string), \\\"final_answer_numerical\\\" (integer).\\n\"\n",
    "        \"No extra text.\\n\\n\"\n",
    "        f\"PROBLEM:\\n{question}\\n\\n\"\n",
    "        f\"ORIGINAL_REASONING_TEMPLATE:\\n{reasoning}\\n\"\n",
    "    )\n",
    "    last_raw = None\n",
    "    for attempt in range(max_retries):\n",
    "        prompt = base_prompt\n",
    "        if attempt > 0:\n",
    "            prompt += \"\\nYour previous answer was not a valid integer. Re-solve and return an integer.\"\n",
    "        raw = query_fn(prompt, model, FINAL_SCHEMA, seed + attempt)\n",
    "        last_raw = raw\n",
    "        state, pred_ans, pred_num, raw_text = _parse_baseline_output(raw)\n",
    "        # Coerce to int if it is an integer-valued float\n",
    "        if pred_num is not None:\n",
    "            try:\n",
    "                if float(pred_num).is_integer():\n",
    "                    return {\n",
    "                        \"gold_num\": int(float(pred_num)),\n",
    "                        \"gold_answer\": pred_ans,\n",
    "                        \"state\": state,\n",
    "                        \"raw\": raw_text,\n",
    "                        \"coerced\": False,\n",
    "                    }\n",
    "            except Exception:\n",
    "                pass\n",
    "    # Final fallback: try to parse last numeric and coerce\n",
    "    gold_num = None\n",
    "    try:\n",
    "        if last_raw is not None:\n",
    "            _, _, pred_num, raw_text = _parse_baseline_output(last_raw)\n",
    "            if pred_num is not None:\n",
    "                gold_num = int(round(float(pred_num)))\n",
    "                return {\n",
    "                    \"gold_num\": gold_num,\n",
    "                    \"gold_answer\": str(pred_num),\n",
    "                    \"state\": None,\n",
    "                    \"raw\": raw_text,\n",
    "                    \"coerced\": True,\n",
    "                }\n",
    "    except Exception:\n",
    "        pass\n",
    "    return {\"gold_num\": None, \"gold_answer\": None, \"state\": None, \"raw\": None, \"coerced\": True}\n",
    "\n",
    "# Build a mutated dataset with new questions and LLM-solved gold numbers\n",
    "def build_mutated_examples(dataset, rng: random.Random, query_fn, model: str, seed: int = 1234):\n",
    "    mutated = []\n",
    "    for idx, ex in enumerate(dataset):\n",
    "        orig_q = ex.get(\"question\", \"\")\n",
    "        orig_a = ex.get(\"answer\", \"\")\n",
    "        reasoning = extract_reasoning(orig_a)\n",
    "        new_q, mapping = mutate_numbers_in_text(orig_q, rng)\n",
    "        solved = solve_gold_with_reasoning(new_q, reasoning, query_fn, model, seed=seed + idx)\n",
    "        gold_num = solved.get(\"gold_num\")\n",
    "        # store a minimal GSM8K-style answer string for parsing\n",
    "        gold_answer = None if gold_num is None else f\"#### {int(gold_num)}\"\n",
    "        mutated.append({\n",
    "            \"question\": new_q,\n",
    "            \"answer\": gold_answer,\n",
    "            \"gold_num\": gold_num,\n",
    "            \"orig_question\": orig_q,\n",
    "            \"orig_answer\": orig_a,\n",
    "            \"orig_reasoning\": reasoning,\n",
    "            \"number_mapping\": mapping,\n",
    "            \"procedure\": procedures_by_row.get(idx),\n",
    "            \"solver_raw\": solved.get(\"raw\"),\n",
    "            \"solver_state\": solved.get(\"state\"),\n",
    "            \"solver_coerced\": solved.get(\"coerced\"),\n",
    "        })\n",
    "    return mutated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf261a71",
   "metadata": {},
   "source": [
    "## ðŸŸ§ **Step 3**: Set variable constants and instantiate necessary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af074d5c",
   "metadata": {},
   "source": [
    "These include:\n",
    "- Defining regex search functions to grab the final numerical answer from the GSM8K `answer` parameter\n",
    "- Defining the evaluation function to compare predicted and actual answers\n",
    "- Defining functions for file and ID handling (for saving results)\n",
    "- Grabbing the GSM final answer schema\n",
    "- Setting the query function\n",
    "- Setting the model\n",
    "- Instantiating the GA (genetic algorithm) object\n",
    "- Defining the run function which puts everything together into one easy-to-run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6865129",
   "metadata": {},
   "outputs": [],
   "source": [
    "_FINAL_AFTER_HASH_RE = re.compile(r\"####\\s*(-?\\d+(?:\\.\\d+)?)\\s*$\", re.MULTILINE)\n",
    "_LAST_NUMBER_RE = re.compile(r\"-?\\d+(?:\\.\\d+)?\")\n",
    "\n",
    "def extract_gold_number(gold_answer):\n",
    "    m = _FINAL_AFTER_HASH_RE.search(gold_answer)\n",
    "    if m:\n",
    "        return float(m.group(1))\n",
    "    nums = _LAST_NUMBER_RE.findall(gold_answer)\n",
    "    return float(nums[-1]) if nums else None\n",
    "\n",
    "def _numbers_equal(a, b, tol=1e-9):\n",
    "    if a is None or b is None:\n",
    "        return False\n",
    "    try:\n",
    "        return abs(float(a) - float(b)) < tol\n",
    "    except Exception:\n",
    "        return a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2beac706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(state) -> float:\n",
    "    \"\"\"Return a fitness score in [0,1].\"\"\"\n",
    "    # prefer model-extracted numeric if present, else try to parse its text\n",
    "    pred_num = state.get(\"final_answer_numerical\")\n",
    "    if pred_num is None:\n",
    "        try:\n",
    "            pred_num = float(re.findall(r\"-?\\d+(?:\\.\\d+)?\", state.get(\"final_answer\",\"\"))[-1])\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    gold_num = state.get(\"_gold_num\")  # weâ€™ll inject this per item\n",
    "    if gold_num is None:\n",
    "        return 0.0\n",
    "    # exact match or close within small tolerance\n",
    "    return 1.0 if math.isclose(pred_num, gold_num, rel_tol=0, abs_tol=1e-6) else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0db9737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_extract_json(text: str) -> Optional[dict]:\n",
    "    \"\"\"Try to pull a JSON object from a string. Returns dict or None.\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    s = text.strip()\n",
    "\n",
    "    # Strip ```json ... ``` fences\n",
    "    fence = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", s, flags=re.DOTALL | re.IGNORECASE)\n",
    "    if fence:\n",
    "        s = fence.group(1).strip()\n",
    "\n",
    "    # Try direct parse\n",
    "    try:\n",
    "        obj = json.loads(s)\n",
    "        return obj if isinstance(obj, dict) else None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback: take the first {...} block\n",
    "    i, j = s.find(\"{\"), s.rfind(\"}\")\n",
    "    if i != -1 and j != -1 and j > i:\n",
    "        try:\n",
    "            obj = json.loads(s[i : j + 1])\n",
    "            return obj if isinstance(obj, dict) else None\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def _parse_baseline_output(raw: Any) -> Tuple[Dict[str, Any], Optional[str], Optional[float], str]:\n",
    "    \"\"\"\n",
    "    Returns (state, pred_answer, pred_num, raw_text).\n",
    "    - state: parsed dict if possible, else {\"final_answer\": <text>}\n",
    "    - pred_answer: state[\"final_answer\"] if available, else the raw text\n",
    "    - pred_num: state[\"final_answer_numerical\"] if available/coercible, else last number in pred_answer\n",
    "    - raw_text: normalized string version of raw\n",
    "    \"\"\"\n",
    "    # Normalize raw_text\n",
    "    if isinstance(raw, dict):\n",
    "        raw_text = json.dumps(raw, ensure_ascii=False)\n",
    "        state = raw\n",
    "    else:\n",
    "        raw_text = \"\" if raw is None else str(raw)\n",
    "        state = _safe_extract_json(raw_text)\n",
    "\n",
    "    if isinstance(state, dict):\n",
    "        pred_answer = state.get(\"final_answer\")\n",
    "        pred_num = state.get(\"final_answer_numerical\")\n",
    "\n",
    "        # Coerce numeric if possible\n",
    "        try:\n",
    "            pred_num = float(pred_num) if pred_num is not None else None\n",
    "        except Exception:\n",
    "            pred_num = None\n",
    "\n",
    "        # If numeric missing, try parse from final_answer text\n",
    "        if pred_num is None:\n",
    "            txt = str(pred_answer or \"\")\n",
    "            nums = _LAST_NUMBER_RE.findall(txt)\n",
    "            pred_num = float(nums[-1]) if nums else None\n",
    "\n",
    "        return state, (str(pred_answer) if pred_answer is not None else None), pred_num, raw_text\n",
    "\n",
    "    # No JSON found: treat as plain text\n",
    "    txt = raw_text.strip()\n",
    "    nums = _LAST_NUMBER_RE.findall(txt)\n",
    "    pred_num = float(nums[-1]) if nums else None\n",
    "    return {\"final_answer\": txt}, (txt if txt else None), pred_num, raw_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1470de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _append_jsonl(path, items):\n",
    "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        for it in items:\n",
    "            f.write(json.dumps(it, ensure_ascii=False) + \"\\n\")\n",
    "        f.flush()\n",
    "        os.fsync(f.fileno())\n",
    "\n",
    "def _load_existing_ids(path):\n",
    "    ids = set()\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                try:\n",
    "                    rec = json.loads(line)\n",
    "                    if \"id\" in rec and rec[\"id\"] is not None:\n",
    "                        ids.add(rec[\"id\"])\n",
    "                except json.JSONDecodeError:\n",
    "                    # tolerate a partially written last line\n",
    "                    continue\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    return ids\n",
    "\n",
    "def _stable_example_id(ex, *, salt=\"\"):\n",
    "    \"\"\"\n",
    "    Make a deterministic ID when dataset lacks 'id'.\n",
    "    Uses question+answer (+ optional salt) to avoid changing if order changes.\n",
    "    \"\"\"\n",
    "    # If a real id exists, reuse it\n",
    "    if ex.get(\"id\") is not None:\n",
    "        return str(ex[\"id\"])\n",
    "\n",
    "    q = (ex.get(\"question\") or \"\").strip()\n",
    "    a = (ex.get(\"answer\") or \"\").strip()\n",
    "    h = blake2b(digest_size=16)  # 128-bit\n",
    "    h.update(salt.encode(\"utf-8\", \"ignore\"))\n",
    "    h.update(q.encode(\"utf-8\", \"ignore\"))\n",
    "    h.update(b\"\\x1e\")  # delimiter\n",
    "    h.update(a.encode(\"utf-8\", \"ignore\"))\n",
    "    return h.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a6d8292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = \"llama4:latest\"\n",
    "# MODEL = \"gemma3:latest\"\n",
    "# MODEL = \"gpt-oss:120b-cloud\"\n",
    "GPT_OSS_LOCAL_BUGGY_MODELS = {\"gpt-oss:20b\", \"gpt-oss:120b\"}\n",
    "MODEL = \"gpt-oss:120b\"\n",
    "FINAL_SCHEMA = get_schema(\"gsm\")\n",
    "QUERY_FN = query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca2057ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_fn_no_format_for_gptoss(prompt, model, fmt, seed):\n",
    "    # kill structured-output / format only for gpt-oss models\n",
    "    # Note, this will only be with the gpt-oss NON-CLOUD models (gpt-oss:120b & gpt-oss:20b)\n",
    "    # Cloud models do not have this bug, so I want to bypass this if it is a cloud model\n",
    "    if isinstance(model, str) and model in GPT_OSS_LOCAL_BUGGY_MODELS:\n",
    "        fmt = None\n",
    "    return QUERY_FN(prompt, model, fmt, seed)   # call your existing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ee1f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunnerFn = Callable[[str, Optional[float]], Dict[str, Any]]\n",
    "\n",
    "def make_baseline_runner(query_fn, model: str, seed: int = 1234, print_bool: bool = False) -> RunnerFn:\n",
    "    def _runner(question: str, gold_num: Optional[float], ex: Optional[dict] = None, idx: Optional[int] = None) -> Dict[str, Any]:\n",
    "        prompt = (\n",
    "            \"Solve the following GSM8K problem.\"\n",
    "            'Return ONLY JSON with keys: \"final_answer\" (string), \"final_answer_numerical\" (number).'\n",
    "            \"No extra text.\"\n",
    "            f\"PROBLEM:{question}\"\n",
    "        )\n",
    "        if print_bool:\n",
    "            print(\"Prompt to model:\")\n",
    "            print(prompt)\n",
    "            print(\"-----\")\n",
    "        raw = query_fn(prompt, model, FINAL_SCHEMA, seed)  # your query_fn can ignore fmt for local gpt-oss\n",
    "        if print_bool:\n",
    "            print(\"Raw model output:\")\n",
    "            print(raw)\n",
    "            print(\"-----\")\n",
    "        state, pred_ans, pred_num, raw_text = _parse_baseline_output(raw)\n",
    "\n",
    "        correct = (\n",
    "            pred_num is not None\n",
    "            and gold_num is not None\n",
    "            and math.isclose(float(pred_num), float(gold_num), rel_tol=0, abs_tol=1e-6)\n",
    "        )\n",
    "        return {\n",
    "            \"mode\": \"baseline\",\n",
    "            \"state\": state,\n",
    "            \"pred_answer\": pred_ans,\n",
    "            \"pred_num\": pred_num,\n",
    "            \"correct\": bool(correct),\n",
    "            \"raw\": raw_text,\n",
    "        }\n",
    "    return _runner\n",
    "\n",
    "# GA-based procedural runner (original)\n",
    "def make_procedural_runner(ga, query_fn, model: str, seed: int = 1234, print_bool: bool = False) -> RunnerFn:\n",
    "    def _runner(question: str, gold_num: Optional[float], ex: Optional[dict] = None, idx: Optional[int] = None) -> Dict[str, Any]:\n",
    "        best, history = ga.run(\n",
    "            task_description=question,\n",
    "            final_answer_schema=FINAL_SCHEMA,\n",
    "            eval_fn=None,\n",
    "            print_progress=print_bool,\n",
    "        )\n",
    "        if print_bool:\n",
    "            print(\"Best procedure found:\")\n",
    "            pretty_print(best.proc)\n",
    "            print(\"Running final procedure to get final answer...\")\n",
    "        final_state = run_steps_stateful_minimal(\n",
    "            best.proc, question, FINAL_SCHEMA, ga.model, print_bool=print_bool, query_fn=query_fn\n",
    "        )\n",
    "        pred_ans = final_state.get(\"final_answer\")\n",
    "        pred_num = final_state.get(\"final_answer_numerical\")\n",
    "        correct = (\n",
    "            pred_num is not None\n",
    "            and gold_num is not None\n",
    "            and math.isclose(float(pred_num), float(gold_num), rel_tol=0, abs_tol=1e-6)\n",
    "        )\n",
    "        return {\n",
    "            \"mode\": \"procedural\",\n",
    "            \"procedure\": best.proc,\n",
    "            \"fitness\": best.fitness,\n",
    "            \"steps\": len(best.proc.get(\"steps\", [])),\n",
    "            \"state\": final_state,\n",
    "            \"pred_answer\": pred_ans,\n",
    "            \"pred_num\": pred_num,\n",
    "            \"correct\": bool(correct),\n",
    "        }\n",
    "    return _runner\n",
    "\n",
    "# Fixed-procedure runner using existing procedures from prior run\n",
    "def make_fixed_procedure_runner(query_fn, model: str, seed: int = 1234, print_bool: bool = False) -> RunnerFn:\n",
    "    def _runner(question: str, gold_num: Optional[float], ex: Optional[dict] = None, idx: Optional[int] = None) -> Dict[str, Any]:\n",
    "        if not ex or ex.get(\"procedure\") is None:\n",
    "            raise ValueError(\"Missing procedure in example for fixed-procedure runner\")\n",
    "        proc = ex.get(\"procedure\")\n",
    "        final_state = run_steps_stateful_minimal(\n",
    "            proc, question, FINAL_SCHEMA, model, print_bool=print_bool, query_fn=query_fn\n",
    "        )\n",
    "        pred_ans = final_state.get(\"final_answer\")\n",
    "        pred_num = final_state.get(\"final_answer_numerical\")\n",
    "        correct = (\n",
    "            pred_num is not None\n",
    "            and gold_num is not None\n",
    "            and math.isclose(float(pred_num), float(gold_num), rel_tol=0, abs_tol=1e-6)\n",
    "        )\n",
    "        return {\n",
    "            \"mode\": \"procedural_fixed\",\n",
    "            \"procedure\": proc,\n",
    "            \"steps\": len(proc.get(\"steps\", [])) if isinstance(proc, dict) else None,\n",
    "            \"state\": final_state,\n",
    "            \"pred_answer\": pred_ans,\n",
    "            \"pred_num\": pred_num,\n",
    "            \"correct\": bool(correct),\n",
    "        }\n",
    "    return _runner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac9fcad",
   "metadata": {},
   "source": [
    "Runners for running the procedural queries vs. the baseline queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e34ffe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gsm8k_batch(\n",
    "    examples,\n",
    "    runner: RunnerFn,       # <-- inject baseline/procedural behavior here\n",
    "    out_path=None,          # e.g., \"runs/gsm8k_results.jsonl\"\n",
    "    save_every=10,          # write every N examples\n",
    "    resume=False,           # skip examples whose IDs are already in out_path\n",
    "    id_salt=\"\",             # optional: add dataset name/split/version here for extra uniqueness\n",
    "    *,\n",
    "    skip_errors: bool = False,          # NEW: continue after per-item failures\n",
    "    save_error_records: bool = True,    # NEW: write an \"error\" record to JSONL\n",
    "    include_traceback: bool = False,    # NEW: optionally store traceback (can be large)\n",
    "    print_bool: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    examples: iterable of dicts like {\"question\": \"...\", \"answer\": \"...\"} (GSM8K format)\n",
    "    Returns: list of per-item result dicts with procedure, state, and score.\n",
    "    Persists results to JSONL every `save_every`. If `resume=True`, skips already-saved IDs.\n",
    "    \"\"\"\n",
    "    pending = []\n",
    "    results = []\n",
    "    existing_ids = _load_existing_ids(out_path) if (resume and out_path) else set()\n",
    "\n",
    "    def _flush():\n",
    "        nonlocal pending\n",
    "        if out_path and pending:\n",
    "            _append_jsonl(out_path, pending)\n",
    "            pending.clear()\n",
    "\n",
    "    for idx, ex in enumerate(examples):\n",
    "        qid = _stable_example_id(ex, salt=id_salt)\n",
    "        if resume and out_path and (qid in existing_ids):\n",
    "            continue\n",
    "\n",
    "        question = ex.get(\"question\")\n",
    "        gold_text = ex.get(\"answer\")\n",
    "        gold_num = ex.get(\"gold_num\")\n",
    "        if gold_num is None:\n",
    "            gold_num = extract_gold_number(gold_text) if gold_text else None\n",
    "\n",
    "        best = None # so the except block is safe\n",
    "        try:\n",
    "            # runner may accept ex/idx; if it doesn't, Python will ignore via default args\n",
    "            extra = runner(question, gold_num, ex=ex, idx=idx)\n",
    "\n",
    "            rec = {\n",
    "                \"id\": qid,\n",
    "                \"row_index\": idx,\n",
    "                \"question\": question,\n",
    "                \"gold_answer\": gold_text,\n",
    "                \"gold_num\": gold_num,\n",
    "                \"status\": \"ok\",\n",
    "                **extra,\n",
    "            }\n",
    "\n",
    "            # include any extra fields from the example for traceability\n",
    "            for k, v in ex.items():\n",
    "                if k in {\"question\", \"answer\"}:\n",
    "                    continue\n",
    "                rec.setdefault(k, v)\n",
    "\n",
    "        except Exception as e:\n",
    "            this_err_proc = getattr(best, \"proc\", None) \n",
    "\n",
    "            if not skip_errors:\n",
    "                # flush anything we have before raising\n",
    "                _flush()\n",
    "                raise\n",
    "\n",
    "            # create an error record (and optionally mark it as \"done\" for resume)\n",
    "            rec = {\n",
    "                \"id\": qid,\n",
    "                \"row_index\": idx,\n",
    "                \"question\": question,\n",
    "                \"gold_answer\": gold_text,\n",
    "                \"gold_num\": gold_num,\n",
    "                \"procedure\": this_err_proc,\n",
    "                \"status\": \"error\",\n",
    "                \"error_type\": type(e).__name__,\n",
    "                \"error\": str(e),\n",
    "                \"timestamp_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "            }\n",
    "            if include_traceback:\n",
    "                rec[\"traceback\"] = traceback.format_exc()\n",
    "\n",
    "            # If you *don't* want resume=True to skip errored items later,\n",
    "            # set save_error_records=False OR change your _load_existing_ids\n",
    "            # to only count status==\"ok\".\n",
    "            if not save_error_records:\n",
    "                # don't save it; still return it in-memory\n",
    "                results.append(rec)\n",
    "                continue\n",
    "\n",
    "        results.append(rec)\n",
    "\n",
    "        if out_path:\n",
    "            pending.append(rec)\n",
    "            if len(pending) >= save_every:\n",
    "                _flush()\n",
    "\n",
    "    _flush()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e256c66b",
   "metadata": {},
   "source": [
    "Runner for running an entire GSM8K batch with file saving IO capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ab7225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gsm8k_batch(\n",
    "    examples,\n",
    "    runner: RunnerFn,       # <-- inject baseline/procedural behavior here\n",
    "    out_path=None,          # e.g., \"runs/gsm8k_results.jsonl\"\n",
    "    save_every=10,          # write every N examples\n",
    "    resume=False,           # skip examples whose IDs are already in out_path\n",
    "    id_salt=\"\",             # optional: add dataset name/split/version here for extra uniqueness\n",
    "    *,\n",
    "    skip_errors: bool = False,          # NEW: continue after per-item failures\n",
    "    save_error_records: bool = True,    # NEW: write an \"error\" record to JSONL\n",
    "    include_traceback: bool = False,    # NEW: optionally store traceback (can be large)\n",
    "    print_bool: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    examples: iterable of dicts like {\"question\": \"...\", \"answer\": \"...\"} (GSM8K format)\n",
    "    Returns: list of per-item result dicts with procedure, state, and score.\n",
    "    Persists results to JSONL every `save_every`. If `resume=True`, skips already-saved IDs.\n",
    "    \"\"\"\n",
    "    pending = []\n",
    "    results = []\n",
    "    existing_ids = _load_existing_ids(out_path) if (resume and out_path) else set()\n",
    "\n",
    "    def _flush():\n",
    "        nonlocal pending\n",
    "        if out_path and pending:\n",
    "            _append_jsonl(out_path, pending)\n",
    "            pending.clear()\n",
    "\n",
    "    for idx, ex in enumerate(examples):\n",
    "        qid = _stable_example_id(ex, salt=id_salt)\n",
    "        if resume and out_path and (qid in existing_ids):\n",
    "            continue\n",
    "\n",
    "        question = ex.get(\"question\")\n",
    "        gold_text = ex.get(\"answer\")\n",
    "        gold_num = extract_gold_number(gold_text) if gold_text else None\n",
    "\n",
    "        best = None # so the except block is safe\n",
    "        try:\n",
    "            extra = runner(question, gold_num)\n",
    "\n",
    "            rec = {\n",
    "                \"id\": qid,\n",
    "                \"row_index\": idx,\n",
    "                \"question\": question,\n",
    "                \"gold_answer\": gold_text,\n",
    "                \"gold_num\": gold_num,\n",
    "                \"status\": \"ok\",\n",
    "                **extra,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            this_err_proc = getattr(best, \"proc\", None) \n",
    "\n",
    "            if not skip_errors:\n",
    "                # flush anything we have before raising\n",
    "                _flush()\n",
    "                raise\n",
    "\n",
    "            # create an error record (and optionally mark it as \"done\" for resume)\n",
    "            rec = {\n",
    "                \"id\": qid,\n",
    "                \"row_index\": idx,\n",
    "                \"question\": question,\n",
    "                \"gold_answer\": gold_text,\n",
    "                \"gold_num\": gold_num,\n",
    "                \"procedure\": this_err_proc,\n",
    "                \"status\": \"error\",\n",
    "                \"error_type\": type(e).__name__,\n",
    "                \"error\": str(e),\n",
    "                \"timestamp_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "            }\n",
    "            if include_traceback:\n",
    "                rec[\"traceback\"] = traceback.format_exc()\n",
    "\n",
    "            # If you *don't* want resume=True to skip errored items later,\n",
    "            # set save_error_records=False OR change your _load_existing_ids\n",
    "            # to only count status==\"ok\".\n",
    "            if not save_error_records:\n",
    "                # don't save it; still return it in-memory\n",
    "                results.append(rec)\n",
    "                continue\n",
    "\n",
    "        results.append(rec)\n",
    "\n",
    "        if out_path:\n",
    "            pending.append(rec)\n",
    "            if len(pending) >= save_every:\n",
    "                _flush()\n",
    "\n",
    "    _flush()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efabf8e",
   "metadata": {},
   "source": [
    "## ðŸŸ§ **Step 4**: Run the batch function to get results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16884ef",
   "metadata": {},
   "source": [
    "Running the first example to make sure everything goes smoothly before running larger batches\n",
    "\n",
    "Uncomment the cells below if you want to test before running the larger set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e1de201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first = train_dataset.select(range(1))\n",
    "\n",
    "# res = ollama.generate(\n",
    "#         model=MODEL,\n",
    "#         prompt=create_procedure_prompt(first[0][\"question\"]),\n",
    "#         format=None,\n",
    "#         options={\"temperature\": 1, \"seed\": 1234},\n",
    "#     )\n",
    "# print(res[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f69ba30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these variables to control current file\n",
    "CURRENT_FILE_PATH = GENERALIZATION_PROC_OUT\n",
    "CURRENT_ID_SALT = \"gsm8k-train-gen-attack-proc\"\n",
    "# CHANGE TO TRUE ONLY IF YOU NEED TO RESUME\n",
    "RESUME = False\n",
    "# CHANGE ONLY IF YOU WANT TO PRINT LOGS AS IT RUNS\n",
    "PRINT_BOOL = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6144d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the runners\n",
    "proc_runner = make_fixed_procedure_runner(query_fn_no_format_for_gptoss, MODEL, seed=1234, print_bool=PRINT_BOOL)\n",
    "baseline_runner = make_baseline_runner(query_fn_no_format_for_gptoss, MODEL, seed=1234, print_bool=PRINT_BOOL)\n",
    "# Set which runner you want to use\n",
    "RUNNER = proc_runner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build mutated examples with LLM-solved gold answers (may take time)\n",
    "import random\n",
    "rng = random.Random(42)\n",
    "mutated_examples = build_mutated_examples(subsample, rng, query_fn_no_format_for_gptoss, MODEL, seed=1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64de42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save mutated examples to a JSON file for reference\n",
    "with open('runs/mutated_examples.json', 'w') as f:\n",
    "    json.dump(mutated_examples, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c38183",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutated_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d945fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_gsm8k_batch(\n",
    "    mutated_examples,\n",
    "    runner=RUNNER,\n",
    "    out_path=CURRENT_FILE_PATH,\n",
    "    save_every=2,\n",
    "    resume=RESUME,\n",
    "    id_salt=CURRENT_ID_SALT,   # optional but nice to set (dataset name/split/version)\n",
    "    skip_errors=True,          # NEW: continue after per-item failures\n",
    "    print_bool=PRINT_BOOL\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run baseline on the same mutated examples\n",
    "CURRENT_FILE_PATH = GENERALIZATION_BASELINE_OUT\n",
    "CURRENT_ID_SALT = \"gsm8k-train-gen-attack-baseline\"\n",
    "RUNNER = baseline_runner\n",
    "results_baseline = run_gsm8k_batch(\n",
    "    mutated_examples,\n",
    "    runner=RUNNER,\n",
    "    out_path=CURRENT_FILE_PATH,\n",
    "    save_every=2,\n",
    "    resume=RESUME,\n",
    "    id_salt=CURRENT_ID_SALT,\n",
    "    skip_errors=True,\n",
    "    print_bool=PRINT_BOOL\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2716271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which results file to analyze\n",
    "CURRENT_FILE_PATH = GENERALIZATION_PROC_OUT  # or GENERALIZATION_BASELINE_OUT\n",
    "read_results = None\n",
    "with open(CURRENT_FILE_PATH, \"r\") as f:\n",
    "    procs = [json.loads(line) for line in f]\n",
    "    read_results = procs\n",
    "    f.close()\n",
    "results_df = pd.DataFrame(read_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f002e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_gsm8k_batch(\n",
    "    subsample, \n",
    "    runner=RUNNER,\n",
    "    out_path=CURRENT_FILE_PATH, \n",
    "    save_every=2,\n",
    "    resume=RESUME,\n",
    "    id_salt=CURRENT_ID_SALT,   # optional but nice to set (dataset name/split/version)\n",
    "    skip_errors=True,          # NEW: continue after per-item failures\n",
    "    print_bool=PRINT_BOOL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91259320",
   "metadata": {},
   "source": [
    "## ðŸŸ§ **Step 5**: Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa14e2d2",
   "metadata": {},
   "source": [
    "Read your results from your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa111236",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_results = None\n",
    "with open(CURRENT_FILE_PATH, \"r\") as f:\n",
    "    procs = [json.loads(line) for line in f]\n",
    "    read_results = procs\n",
    "    f.close()\n",
    "results_df = pd.DataFrame(read_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4be118d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'correct'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'correct'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcorrect\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.value_counts())\n\u001b[32m      2\u001b[39m results_df[\u001b[33m\"\u001b[39m\u001b[33mcorrect\u001b[39m\u001b[33m\"\u001b[39m].value_counts().plot(kind=\u001b[33m'\u001b[39m\u001b[33mbar\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'correct'"
     ]
    }
   ],
   "source": [
    "print(results_df[\"correct\"].value_counts())\n",
    "results_df[\"correct\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c6cc04",
   "metadata": {},
   "source": [
    "Printing to further investigate false answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeff996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\n",
      "Gold Answer: In the beginning, Betty has only 100 / 2 = $<<100/2=50>>50.\n",
      "Betty's grandparents gave her 15 * 2 = $<<15*2=30>>30.\n",
      "This means, Betty needs 100 - 50 - 30 - 15 = $<<100-50-30-15=5>>5 more.\n",
      "#### 5\n",
      "Predicted Answer: Betty needs $30 more to buy the wallet.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate how much more money Betty needs. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem text from the input.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - problem_text: The problem description.\n",
      "\n",
      "Step 2: Calculate the amount Betty has.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - money_she_has: The amount of money Betty has.\n",
      "\n",
      "Step 3: Calculate the amount Betty needs.\n",
      "  **Inputs**:\n",
      "    - money_she_has: The amount of money Betty has.\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - money_she_needs: The amount of money Betty needs.\n",
      "\n",
      "Step 4: Calculate how much more money Betty needs.\n",
      "  **Inputs**:\n",
      "    - money_she_needs: The amount of money Betty needs.\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - final_answer: The final answer.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\n",
      "Gold Answer: Maila read 12 x 2 = <<12*2=24>>24 pages today.\n",
      "So she was able to read a total of 12 + 24 = <<12+24=36>>36 pages since yesterday.\n",
      "There are 120 - 36 = <<120-36=84>>84 pages left to be read.\n",
      "Since she wants to read half of the remaining pages tomorrow, then she should read 84/2 = <<84/2=42>>42 pages.\n",
      "#### 42\n",
      "Predicted Answer: Julie will read 120 pages tomorrow.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate the number of pages Julie will read tomorrow. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the total number of pages in the book from the problem text.\n",
      "  **Inputs**:\n",
      "    - problem_text: The text of the problem.\n",
      "  **Outputs**:\n",
      "    - total_pages: The total number of pages in the book.\n",
      "\n",
      "Step 2: Calculate the number of pages read yesterday.\n",
      "  **Inputs**:\n",
      "    - total_pages: The total number of pages in the book.\n",
      "  **Outputs**:\n",
      "    - yesterdays_pages: The number of pages read yesterday.\n",
      "\n",
      "Step 3: Calculate the number of pages read today.\n",
      "  **Inputs**:\n",
      "    - total_pages: The total number of pages in the book.\n",
      "    - yesterdays_pages: The number of pages read yesterday.\n",
      "  **Outputs**:\n",
      "    - todays_pages: The number of pages read today.\n",
      "\n",
      "Step 4: Calculate the number of pages Julie will read tomorrow.\n",
      "  **Inputs**:\n",
      "    - todays_pages: The number of pages read today.\n",
      "    - yesterdays_pages: The number of pages read yesterday.\n",
      "  **Outputs**:\n",
      "    - tomorrows_pages: The number of pages Julie will read tomorrow.\n",
      "\n",
      "Step 5: Determine the number of pages Julie will read tomorrow.\n",
      "  **Inputs**:\n",
      "    - tomorrows_pages: The number of pages Julie will read tomorrow.\n",
      "  **Outputs**:\n",
      "    - final_answer: The final answer.\n",
      "\n",
      "---\n",
      "\n",
      "Question: James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\n",
      "Gold Answer: He writes each friend 3*2=<<3*2=6>>6 pages a week\n",
      "So he writes 6*2=<<6*2=12>>12 pages every week\n",
      "That means he writes 12*52=<<12*52=624>>624 pages a year\n",
      "#### 624\n",
      "Predicted Answer: The final answer is 104.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate the total pages James writes in a year. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem description from the input variable.\n",
      "  **Inputs**:\n",
      "    - problem_text: Input variable containing the problem description.\n",
      "  **Outputs**:\n",
      "    - problem_description: The extracted problem description.\n",
      "\n",
      "Step 2: Calculate the number of letters James writes per week.\n",
      "  **Inputs**:\n",
      "    - problem_description: Problem description containing the letter writing details.\n",
      "  **Outputs**:\n",
      "    - letters_per_week: The number of letters James writes per week.\n",
      "\n",
      "Step 3: Calculate the number of pages James writes per week.\n",
      "  **Inputs**:\n",
      "    - letters_per_week: The number of letters James writes per week.\n",
      "  **Outputs**:\n",
      "    - pages_per_week: The number of pages James writes per week.\n",
      "\n",
      "Step 4: Calculate the number of pages James writes per year.\n",
      "  **Inputs**:\n",
      "    - pages_per_week: The number of pages James writes per week.\n",
      "  **Outputs**:\n",
      "    - pages_per_year: The total number of pages James writes per year.\n",
      "\n",
      "Step 5: Output the final answer.\n",
      "  **Inputs**:\n",
      "    - pages_per_year: The total number of pages James writes per year.\n",
      "  **Outputs**:\n",
      "    - final_answer: The final answer: the total number of pages James writes in a year.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?\n",
      "Gold Answer: There are 80/100 * 10 = <<80/100*10=8>>8 more purple flowers than yellow flowers.\n",
      "So in Mark's garden, there are 10 + 8 = <<10+8=18>>18 purple flowers.\n",
      "Purple and yellow flowers sum up to 10 + 18 = <<10+18=28>>28 flowers.\n",
      "That means in Mark's garden there are 25/100 * 28 = <<25/100*28=7>>7 green flowers.\n",
      "So in total Mark has 28 + 7 = <<28+7=35>>35 plants in his garden.\n",
      "#### 35\n",
      "Predicted Answer: The total number of flowers is 140 + 60 = 200.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate the total number of flowers in the garden. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem text from the input.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem description\n",
      "  **Outputs**:\n",
      "    - problem_text: The problem text\n",
      "\n",
      "Step 2: Calculate the number of purple flowers.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text\n",
      "  **Outputs**:\n",
      "    - purple_flowers: The number of purple flowers\n",
      "\n",
      "Step 3: Calculate 80% more than the number of yellow flowers.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text\n",
      "    - purple_flowers: The number of purple flowers\n",
      "  **Outputs**:\n",
      "    - yellow_plus_80: The number of yellow flowers plus 80% more\n",
      "\n",
      "Step 4: Calculate the number of green flowers.\n",
      "  **Inputs**:\n",
      "    - yellow_plus_80: The number of yellow flowers plus 80% more\n",
      "    - purple_flowers: The number of purple flowers\n",
      "  **Outputs**:\n",
      "    - green_flowers: The number of green flowers\n",
      "\n",
      "Step 5: Calculate the total number of flowers.\n",
      "  **Inputs**:\n",
      "    - yellow_plus_80: The number of yellow flowers plus 80% more\n",
      "    - purple_flowers: The number of purple flowers\n",
      "    - green_flowers: The number of green flowers\n",
      "  **Outputs**:\n",
      "    - final_answer: The total number of flowers in the garden\n",
      "\n",
      "---\n",
      "\n",
      "Question: Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\n",
      "Gold Answer: He eats 32 from the largest pizzas because 2 x 16 = <<2*16=32>>32\n",
      "He eats 16 from the small pizza because 2 x 8 = <<2*8=16>>16\n",
      "He eats 48 pieces because 32 + 16 = <<32+16=48>>48\n",
      "#### 48\n",
      "Predicted Answer: The final number of slices is 34.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate the total number of pizza slices. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem text from the global state.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - problem_text: The extracted problem text.\n",
      "\n",
      "Step 2: Calculate the total number of slices from large pizzas.\n",
      "  **Inputs**:\n",
      "    - problem_text: The extracted problem text.\n",
      "  **Outputs**:\n",
      "    - slices_from_large: Number of slices from large pizzas.\n",
      "\n",
      "Step 3: Calculate the total number of slices from small pizzas.\n",
      "  **Inputs**:\n",
      "    - problem_text: The extracted problem text.\n",
      "  **Outputs**:\n",
      "    - slices_from_small: Number of slices from small pizzas.\n",
      "\n",
      "Step 4: Calculate the total number of slices.\n",
      "  **Inputs**:\n",
      "    - slices_from_large: Number of slices from large pizzas.\n",
      "    - slices_from_small: Number of slices from small pizzas.\n",
      "  **Outputs**:\n",
      "    - total_slices: The total number of pizza slices.\n",
      "\n",
      "Step 5: Output the final answer.\n",
      "  **Inputs**:\n",
      "    - total_slices: The total number of pizza slices.\n",
      "  **Outputs**:\n",
      "    - final_answer: The final answer in a descriptive form.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Alexis is applying for a new job and bought a new set of business clothes to wear to the interview. She went to a department store with a budget of $200 and spent $30 on a button-up shirt, $46 on suit pants, $38 on a suit coat, $11 on socks, and $18 on a belt. She also purchased a pair of shoes, but lost the receipt for them. She has $16 left from her budget. How much did Alexis pay for the shoes?\n",
      "Gold Answer: Let S be the amount Alexis paid for the shoes.\n",
      "She spent S + 30 + 46 + 38 + 11 + 18 = S + <<+30+46+38+11+18=143>>143.\n",
      "She used all but $16 of her budget, so S + 143 = 200 - 16 = 184.\n",
      "Thus, Alexis paid S = 184 - 143 = $<<184-143=41>>41 for the shoes.\n",
      "#### 41\n",
      "Predicted Answer: The amount spent on the shoes is $89.99.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate the cost of the shoes. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem text from the input.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text to be processed.\n",
      "  **Outputs**:\n",
      "\n",
      "Step 2: Calculate the total cost of the other items.\n",
      "  **Inputs**:\n",
      "  **Outputs**:\n",
      "\n",
      "Step 3: Calculate the amount spent on the shoes.\n",
      "  **Inputs**:\n",
      "  **Outputs**:\n",
      "    - final_answer: The final answer to the problem.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\n",
      "Gold Answer: She works 8 hours a day for $18 per hour so she makes 8*18 = $<<8*18=144.00>>144.00 per 8-hour shift\n",
      "She works 10 hours a day and anything over 8 hours is eligible for overtime, so she gets 10-8 = <<10-8=2>>2 hours of overtime\n",
      "Overtime is calculated as time and a half so and she makes $18/hour so her overtime pay is 18*.5 = $<<18*.5=9.00>>9.00\n",
      "Her overtime pay is 18+9 = $<<18+9=27.00>>27.00\n",
      "Her base pay is $144.00 per 8-hour shift and she works 5 days and makes 5 * $144 = $<<144*5=720.00>>720.00\n",
      "Her overtime pay is $27.00 per hour and she works 2 hours of overtime per day and makes 27*2 = $<<27*2=54.00>>54.00 in overtime pay\n",
      "2 hours of overtime pay for 5 days means she makes 54*5 = $270.00\n",
      "In 5 days her base pay is $720.00 and she makes $270.00 in overtime pay so she makes $720 + $270 = $<<720+270=990.00>>990.00\n",
      "#### 990\n",
      "Predicted Answer: Tina makes $2250.00.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate Tina's total earnings. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem text from the input.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - problem_text: The problem text.\n",
      "\n",
      "Step 2: Calculate the regular earnings for 5 days at 10 hours per day.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text.\n",
      "  **Outputs**:\n",
      "    - total_hours: Total hours worked.\n",
      "\n",
      "Step 3: Calculate the overtime hours. Overtime is paid for hours worked over 8.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text.\n",
      "    - total_hours: Total hours worked.\n",
      "  **Outputs**:\n",
      "    - overtime_hours: Hours worked in overtime.\n",
      "\n",
      "Step 4: Calculate the overtime rate.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text.\n",
      "    - total_hours: Total hours worked.\n",
      "    - overtime_hours: Hours worked in overtime.\n",
      "  **Outputs**:\n",
      "    - overtime_rate: Overtime rate.\n",
      "\n",
      "Step 5: Calculate the total earnings.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text.\n",
      "    - total_hours: Total hours worked.\n",
      "    - overtime_rate: Overtime rate.\n",
      "  **Outputs**:\n",
      "    - final_answer: The final earnings calculation.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "false_answers = results_df[~results_df[\"correct\"]]\n",
    "for index, row in false_answers.iterrows():\n",
    "    print(f\"Question: {row['question']}\")\n",
    "    print(f\"Gold Answer: {row['gold_answer']}\")\n",
    "    print(f\"Predicted Answer: {row['pred_answer']}\")\n",
    "    print(\"Procedure:\")\n",
    "    pretty_print(row['procedure'])\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f57f1d",
   "metadata": {},
   "source": [
    "Looking at an isolated false answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d097c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 1] inputs: {'problem_text': 'Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?'}\n",
      "[step 1] outputs: {k: state[k] for k in ['total_pages'] if k in state}\n",
      "[step 2] inputs: {'total_pages': 120}\n",
      "[step 2] outputs: {k: state[k] for k in ['yesterdays_pages'] if k in state}\n",
      "[step 3] inputs: {'total_pages': 120, 'yesterdays_pages': 0}\n",
      "[step 3] outputs: {k: state[k] for k in ['todays_pages'] if k in state}\n",
      "[step 4] inputs: {'todays_pages': 120, 'yesterdays_pages': 0}\n",
      "[step 4] outputs: {k: state[k] for k in ['tomorrows_pages'] if k in state}\n",
      "[step 5] inputs: {'tomorrows_pages': 120}\n",
      "[step 5] outputs: {k: state[k] for k in ['final_answer', 'final_answer_numerical', 'confidence', 'units'] if k in state}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'problem_text': 'Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?',\n",
       " 'total_pages': 120,\n",
       " 'yesterdays_pages': 0,\n",
       " 'todays_pages': 120,\n",
       " 'tomorrows_pages': 120,\n",
       " 'final_answer': 'Julie will read 120 pages tomorrow.',\n",
       " 'final_answer_numerical': 120,\n",
       " 'confidence': 1,\n",
       " 'units': 'pages'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this = false_answers.iloc[1]\n",
    "run_steps_stateful_minimal(this['procedure'], this['question'], FINAL_SCHEMA, ga.model, print_bool=True, query_fn=QUERY_FN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evoproc_tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
