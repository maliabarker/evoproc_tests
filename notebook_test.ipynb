{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e350c961",
   "metadata": {},
   "source": [
    "# ðŸ§¡ Generating **EvoProc** procedures for the **GSM8K Dataset** Using a Genetic Algorithm and OLLaMa Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ad3473",
   "metadata": {},
   "source": [
    "## ðŸŸ§ **Step 1**: Import packages and necessary application functions & variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08cc3cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, re, math, json, ollama, traceback\n",
    "import pandas as pd\n",
    "from hashlib import blake2b\n",
    "from datetime import datetime, timezone\n",
    "from datasets import load_dataset\n",
    "from typing import Callable, Literal, Optional, Dict, Any, Tuple\n",
    "from evoproc.ga_scaffold_structured import ProcedureGA, GAConfig\n",
    "from evoproc.validators import validate_procedure_structured\n",
    "from evoproc_procedures.models import Procedure\n",
    "from evoproc_procedures.schemas import get_schema\n",
    "from evoproc_procedures.prompts import create_procedure_prompt\n",
    "from evoproc_procedures.ollama import query, query_gpt_chat, repair_fn_ollama\n",
    "from evoproc_procedures.runners import run_steps_stateful_minimal\n",
    "from evoproc_procedures.helpers import pretty_print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afda795",
   "metadata": {},
   "source": [
    "## ðŸŸ§ **Step 2**: Import the GSM8K Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661e6381",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"openai/gsm8k\", \"main\", split=\"train\")\n",
    "test_dataset = load_dataset(\"openai/gsm8k\", \"main\", split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf261a71",
   "metadata": {},
   "source": [
    "## ðŸŸ§ **Step 3**: Set variable constants and instantiate necessary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af074d5c",
   "metadata": {},
   "source": [
    "These include:\n",
    "- Defining regex search functions to grab the final numerical answer from the GSM8K `answer` parameter\n",
    "- Defining the evaluation function to compare predicted and actual answers\n",
    "- Defining functions for file and ID handling (for saving results)\n",
    "- Grabbing the GSM final answer schema\n",
    "- Setting the query function\n",
    "- Setting the model\n",
    "- Instantiating the GA (genetic algorithm) object\n",
    "- Defining the run function which puts everything together into one easy-to-run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6865129",
   "metadata": {},
   "outputs": [],
   "source": [
    "_FINAL_AFTER_HASH_RE = re.compile(r\"####\\s*(-?\\d+(?:\\.\\d+)?)\\s*$\", re.MULTILINE)\n",
    "_LAST_NUMBER_RE = re.compile(r\"-?\\d+(?:\\.\\d+)?\")\n",
    "\n",
    "def extract_gold_number(gold_answer):\n",
    "    m = _FINAL_AFTER_HASH_RE.search(gold_answer)\n",
    "    if m:\n",
    "        return float(m.group(1))\n",
    "    nums = _LAST_NUMBER_RE.findall(gold_answer)\n",
    "    return float(nums[-1]) if nums else None\n",
    "\n",
    "def _numbers_equal(a, b, tol=1e-9):\n",
    "    if a is None or b is None:\n",
    "        return False\n",
    "    try:\n",
    "        return abs(float(a) - float(b)) < tol\n",
    "    except Exception:\n",
    "        return a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2beac706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(state) -> float:\n",
    "    \"\"\"Return a fitness score in [0,1].\"\"\"\n",
    "    # prefer model-extracted numeric if present, else try to parse its text\n",
    "    pred_num = state.get(\"final_answer_numerical\")\n",
    "    if pred_num is None:\n",
    "        try:\n",
    "            pred_num = float(re.findall(r\"-?\\d+(?:\\.\\d+)?\", state.get(\"final_answer\",\"\"))[-1])\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    gold_num = state.get(\"_gold_num\")  # weâ€™ll inject this per item\n",
    "    if gold_num is None:\n",
    "        return 0.0\n",
    "    # exact match or close within small tolerance\n",
    "    return 1.0 if math.isclose(pred_num, gold_num, rel_tol=0, abs_tol=1e-6) else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0db9737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_extract_json(text: str) -> Optional[dict]:\n",
    "    \"\"\"Try to pull a JSON object from a string. Returns dict or None.\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    s = text.strip()\n",
    "\n",
    "    # Strip ```json ... ``` fences\n",
    "    fence = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", s, flags=re.DOTALL | re.IGNORECASE)\n",
    "    if fence:\n",
    "        s = fence.group(1).strip()\n",
    "\n",
    "    # Try direct parse\n",
    "    try:\n",
    "        obj = json.loads(s)\n",
    "        return obj if isinstance(obj, dict) else None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback: take the first {...} block\n",
    "    i, j = s.find(\"{\"), s.rfind(\"}\")\n",
    "    if i != -1 and j != -1 and j > i:\n",
    "        try:\n",
    "            obj = json.loads(s[i : j + 1])\n",
    "            return obj if isinstance(obj, dict) else None\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def _parse_baseline_output(raw: Any) -> Tuple[Dict[str, Any], Optional[str], Optional[float], str]:\n",
    "    \"\"\"\n",
    "    Returns (state, pred_answer, pred_num, raw_text).\n",
    "    - state: parsed dict if possible, else {\"final_answer\": <text>}\n",
    "    - pred_answer: state[\"final_answer\"] if available, else the raw text\n",
    "    - pred_num: state[\"final_answer_numerical\"] if available/coercible, else last number in pred_answer\n",
    "    - raw_text: normalized string version of raw\n",
    "    \"\"\"\n",
    "    # Normalize raw_text\n",
    "    if isinstance(raw, dict):\n",
    "        raw_text = json.dumps(raw, ensure_ascii=False)\n",
    "        state = raw\n",
    "    else:\n",
    "        raw_text = \"\" if raw is None else str(raw)\n",
    "        state = _safe_extract_json(raw_text)\n",
    "\n",
    "    if isinstance(state, dict):\n",
    "        pred_answer = state.get(\"final_answer\")\n",
    "        pred_num = state.get(\"final_answer_numerical\")\n",
    "\n",
    "        # Coerce numeric if possible\n",
    "        try:\n",
    "            pred_num = float(pred_num) if pred_num is not None else None\n",
    "        except Exception:\n",
    "            pred_num = None\n",
    "\n",
    "        # If numeric missing, try parse from final_answer text\n",
    "        if pred_num is None:\n",
    "            txt = str(pred_answer or \"\")\n",
    "            nums = _LAST_NUMBER_RE.findall(txt)\n",
    "            pred_num = float(nums[-1]) if nums else None\n",
    "\n",
    "        return state, (str(pred_answer) if pred_answer is not None else None), pred_num, raw_text\n",
    "\n",
    "    # No JSON found: treat as plain text\n",
    "    txt = raw_text.strip()\n",
    "    nums = _LAST_NUMBER_RE.findall(txt)\n",
    "    pred_num = float(nums[-1]) if nums else None\n",
    "    return {\"final_answer\": txt}, (txt if txt else None), pred_num, raw_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1470de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _append_jsonl(path, items):\n",
    "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        for it in items:\n",
    "            f.write(json.dumps(it, ensure_ascii=False) + \"\\n\")\n",
    "        f.flush()\n",
    "        os.fsync(f.fileno())\n",
    "\n",
    "def _load_existing_ids(path):\n",
    "    ids = set()\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                try:\n",
    "                    rec = json.loads(line)\n",
    "                    if \"id\" in rec and rec[\"id\"] is not None:\n",
    "                        ids.add(rec[\"id\"])\n",
    "                except json.JSONDecodeError:\n",
    "                    # tolerate a partially written last line\n",
    "                    continue\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    return ids\n",
    "\n",
    "def _stable_example_id(ex, *, salt=\"\"):\n",
    "    \"\"\"\n",
    "    Make a deterministic ID when dataset lacks 'id'.\n",
    "    Uses question+answer (+ optional salt) to avoid changing if order changes.\n",
    "    \"\"\"\n",
    "    # If a real id exists, reuse it\n",
    "    if ex.get(\"id\") is not None:\n",
    "        return str(ex[\"id\"])\n",
    "\n",
    "    q = (ex.get(\"question\") or \"\").strip()\n",
    "    a = (ex.get(\"answer\") or \"\").strip()\n",
    "    h = blake2b(digest_size=16)  # 128-bit\n",
    "    h.update(salt.encode(\"utf-8\", \"ignore\"))\n",
    "    h.update(q.encode(\"utf-8\", \"ignore\"))\n",
    "    h.update(b\"\\x1e\")  # delimiter\n",
    "    h.update(a.encode(\"utf-8\", \"ignore\"))\n",
    "    return h.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a6d8292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = \"llama4:latest\"\n",
    "# MODEL = \"gemma3:latest\"\n",
    "# MODEL = \"gpt-oss:120b-cloud\"\n",
    "GPT_OSS_LOCAL_BUGGY_MODELS = {\"gpt-oss:20b\", \"gpt-oss:120b\"}\n",
    "MODEL = \"gpt-oss:120b\"\n",
    "FINAL_SCHEMA = get_schema(\"gsm\")\n",
    "QUERY_FN = query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca2057ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_fn_no_format_for_gptoss(prompt, model, fmt, seed):\n",
    "    # kill structured-output / format only for gpt-oss models\n",
    "    # Note, this will only be with the gpt-oss NON-CLOUD models (gpt-oss:120b & gpt-oss:20b)\n",
    "    # Cloud models do not have this bug, so I want to bypass this if it is a cloud model\n",
    "    if isinstance(model, str) and model in GPT_OSS_LOCAL_BUGGY_MODELS:\n",
    "        fmt = None\n",
    "    return QUERY_FN(prompt, model, fmt, seed)   # call your existing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ee1f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ga = ProcedureGA(\n",
    "#     model=MODEL,\n",
    "#     create_proc_fn=lambda task: create_procedure_prompt(task),\n",
    "#     query_fn=QUERY_FN,                                     # backend call\n",
    "#     schema_json_fn=lambda: Procedure.model_json_schema(),\n",
    "#     validate_fn=validate_procedure_structured,          # pure function\n",
    "#     repair_fn=repair_fn_ollama,                         # GA expects (proc, model) -> proc\n",
    "#     cfg=GAConfig(population_size=3, max_generations=3, crossover_rate=0.5, mutation_rate=0.5, seed=42),\n",
    "# )\n",
    "\n",
    "ga = ProcedureGA(\n",
    "    model=MODEL,\n",
    "    create_proc_fn=lambda task: create_procedure_prompt(task),\n",
    "    query_fn=query_fn_no_format_for_gptoss,             # backend call\n",
    "    schema_json_fn=lambda: None,\n",
    "    validate_fn=validate_procedure_structured,          # pure function\n",
    "    repair_fn=repair_fn_ollama,                         # GA expects (proc, model) -> proc\n",
    "    cfg=GAConfig(population_size=3, max_generations=3, crossover_rate=0.5, mutation_rate=0.5, seed=42),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac9fcad",
   "metadata": {},
   "source": [
    "Runners for running the procedural queries vs. the baseline queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e34ffe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunnerFn = Callable[[str, Optional[float]], Dict[str, Any]]\n",
    "\n",
    "def make_baseline_runner(query_fn, model: str, seed: int = 1234, print_bool: bool = False) -> RunnerFn:\n",
    "    def _runner(question: str, gold_num: Optional[float]) -> Dict[str, Any]:\n",
    "        prompt = (\n",
    "            \"Solve the following GSM8K problem.\\n\"\n",
    "            'Return ONLY JSON with keys: \"final_answer\" (string), \"final_answer_numerical\" (number).\\n'\n",
    "            \"No extra text.\\n\\n\"\n",
    "            f\"PROBLEM:\\n{question}\\n\"\n",
    "        )\n",
    "        if print_bool:\n",
    "            print(\"Prompt to model:\")\n",
    "            print(prompt)\n",
    "            print(\"-----\")\n",
    "        raw = query_fn(prompt, model, FINAL_SCHEMA, seed)  # your query_fn can ignore fmt for local gpt-oss\n",
    "        if print_bool:\n",
    "            print(\"Raw model output:\")\n",
    "            print(raw)\n",
    "            print(\"-----\")\n",
    "        state, pred_ans, pred_num, raw_text = _parse_baseline_output(raw)\n",
    "\n",
    "        correct = (\n",
    "            pred_num is not None\n",
    "            and gold_num is not None\n",
    "            and math.isclose(float(pred_num), float(gold_num), rel_tol=0, abs_tol=1e-6)\n",
    "        )\n",
    "        return {\n",
    "            \"mode\": \"baseline\",\n",
    "            \"state\": state,\n",
    "            \"pred_answer\": pred_ans,\n",
    "            \"pred_num\": pred_num,\n",
    "            \"correct\": bool(correct),\n",
    "            \"raw\": raw_text,\n",
    "        }\n",
    "    return _runner\n",
    "\n",
    "def make_procedural_runner(ga, query_fn, model: str, seed: int = 1234, print_bool: bool = False) -> RunnerFn:\n",
    "    def _runner(question: str, gold_num: Optional[float]) -> Dict[str, Any]:\n",
    "        best, history = ga.run(\n",
    "            task_description=question,\n",
    "            final_answer_schema=FINAL_SCHEMA,\n",
    "            eval_fn=None,\n",
    "            print_progress=print_bool,\n",
    "        )\n",
    "        if print_bool:\n",
    "            print(\"\\nBest procedure found:\")\n",
    "            pretty_print(best.proc)\n",
    "            print(\"\\nRunning final procedure to get final answer...\")\n",
    "        final_state = run_steps_stateful_minimal(\n",
    "            best.proc, question, FINAL_SCHEMA, ga.model, query_fn=query_fn\n",
    "        )\n",
    "        pred_ans = final_state.get(\"final_answer\")\n",
    "        pred_num = final_state.get(\"final_answer_numerical\")\n",
    "        correct = (\n",
    "            pred_num is not None\n",
    "            and gold_num is not None\n",
    "            and math.isclose(float(pred_num), float(gold_num), rel_tol=0, abs_tol=1e-6)\n",
    "        )\n",
    "        return {\n",
    "            \"mode\": \"procedural\",\n",
    "            \"procedure\": best.proc,\n",
    "            \"fitness\": best.fitness,\n",
    "            \"steps\": len(best.proc.get(\"steps\", [])),\n",
    "            \"state\": final_state,\n",
    "            \"pred_answer\": pred_ans,\n",
    "            \"pred_num\": pred_num,\n",
    "            \"correct\": bool(correct),\n",
    "        }\n",
    "    return _runner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e256c66b",
   "metadata": {},
   "source": [
    "Runner for running an entire GSM8K batch with file saving IO capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ab7225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gsm8k_batch(\n",
    "    examples,\n",
    "    runner: RunnerFn,       # <-- inject baseline/procedural behavior here\n",
    "    out_path=None,          # e.g., \"runs/gsm8k_results.jsonl\"\n",
    "    save_every=10,          # write every N examples\n",
    "    resume=False,           # skip examples whose IDs are already in out_path\n",
    "    id_salt=\"\",             # optional: add dataset name/split/version here for extra uniqueness\n",
    "    *,\n",
    "    skip_errors: bool = False,          # NEW: continue after per-item failures\n",
    "    save_error_records: bool = True,    # NEW: write an \"error\" record to JSONL\n",
    "    include_traceback: bool = False,    # NEW: optionally store traceback (can be large)\n",
    "    print_bool: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    examples: iterable of dicts like {\"question\": \"...\", \"answer\": \"...\"} (GSM8K format)\n",
    "    Returns: list of per-item result dicts with procedure, state, and score.\n",
    "    Persists results to JSONL every `save_every`. If `resume=True`, skips already-saved IDs.\n",
    "    \"\"\"\n",
    "    pending = []\n",
    "    results = []\n",
    "    existing_ids = _load_existing_ids(out_path) if (resume and out_path) else set()\n",
    "\n",
    "    def _flush():\n",
    "        nonlocal pending\n",
    "        if out_path and pending:\n",
    "            _append_jsonl(out_path, pending)\n",
    "            pending.clear()\n",
    "\n",
    "    for idx, ex in enumerate(examples):\n",
    "        qid = _stable_example_id(ex, salt=id_salt)\n",
    "        if resume and out_path and (qid in existing_ids):\n",
    "            continue\n",
    "\n",
    "        question = ex.get(\"question\")\n",
    "        gold_text = ex.get(\"answer\")\n",
    "        gold_num = extract_gold_number(gold_text) if gold_text else None\n",
    "\n",
    "        best = None # so the except block is safe\n",
    "        try:\n",
    "            extra = runner(question, gold_num)\n",
    "\n",
    "            rec = {\n",
    "                \"id\": qid,\n",
    "                \"row_index\": idx,\n",
    "                \"question\": question,\n",
    "                \"gold_answer\": gold_text,\n",
    "                \"gold_num\": gold_num,\n",
    "                \"status\": \"ok\",\n",
    "                **extra,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            this_err_proc = getattr(best, \"proc\", None) \n",
    "\n",
    "            if not skip_errors:\n",
    "                # flush anything we have before raising\n",
    "                _flush()\n",
    "                raise\n",
    "\n",
    "            # create an error record (and optionally mark it as \"done\" for resume)\n",
    "            rec = {\n",
    "                \"id\": qid,\n",
    "                \"row_index\": idx,\n",
    "                \"question\": question,\n",
    "                \"gold_answer\": gold_text,\n",
    "                \"gold_num\": gold_num,\n",
    "                \"procedure\": this_err_proc,\n",
    "                \"status\": \"error\",\n",
    "                \"error_type\": type(e).__name__,\n",
    "                \"error\": str(e),\n",
    "                \"timestamp_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "            }\n",
    "            if include_traceback:\n",
    "                rec[\"traceback\"] = traceback.format_exc()\n",
    "\n",
    "            # If you *don't* want resume=True to skip errored items later,\n",
    "            # set save_error_records=False OR change your _load_existing_ids\n",
    "            # to only count status==\"ok\".\n",
    "            if not save_error_records:\n",
    "                # don't save it; still return it in-memory\n",
    "                results.append(rec)\n",
    "                continue\n",
    "\n",
    "        results.append(rec)\n",
    "\n",
    "        if out_path:\n",
    "            pending.append(rec)\n",
    "            if len(pending) >= save_every:\n",
    "                _flush()\n",
    "\n",
    "    _flush()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efabf8e",
   "metadata": {},
   "source": [
    "## ðŸŸ§ **Step 4**: Run the batch function to get results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16884ef",
   "metadata": {},
   "source": [
    "Running the first example to make sure everything goes smoothly before running larger batches\n",
    "\n",
    "Uncomment the cells below if you want to test before running the larger set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e1de201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first = train_dataset.select(range(1))\n",
    "\n",
    "# res = ollama.generate(\n",
    "#         model=MODEL,\n",
    "#         prompt=create_procedure_prompt(first[0][\"question\"]),\n",
    "#         format=None,\n",
    "#         options={\"temperature\": 1, \"seed\": 1234},\n",
    "#     )\n",
    "# print(res[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f69ba30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # just a small batch for demo, run if you want to test quickly\n",
    "# first = train_dataset.select(range(1))  \n",
    "# first_result = run_gsm8k_batch(\n",
    "#     first,\n",
    "#     runner=make_baseline_runner(query_fn_no_format_for_gptoss, MODEL, seed=1234, print_bool=True),\n",
    "#     out_path=\"runs/gsm8k_results_testing.jsonl\",\n",
    "#     save_every=1,  # write every example for demo\n",
    "#     id_salt=\"gsm8k_train\",  # optional: add dataset name/split/version here for extra uniqueness\n",
    "#     print_bool=True\n",
    "# )\n",
    "# print(first_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6144d8ad",
   "metadata": {},
   "source": [
    "Running the actual data set (full). Adjust params below if needed before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d945fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these variables to control current file\n",
    "CURRENT_FILE_PATH = \"runs/gsm8k_train_v6_baseline.jsonl\"\n",
    "CURRENT_ID_SALT = \"gsm8k-train-v6_baseline\"\n",
    "# CHANGE TO TRUE ONLY IF YOU NEED TO RESUME\n",
    "RESUME = False\n",
    "# CHANGE ONLY IF YOU WANT TO PRINT LOGS AS IT RUNS\n",
    "PRINT_BOOL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2716271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the runners\n",
    "proc_runner = make_procedural_runner(ga, query_fn_no_format_for_gptoss, MODEL, seed=1234, print_bool=PRINT_BOOL)\n",
    "baseline_runner = make_baseline_runner(query_fn_no_format_for_gptoss, MODEL, seed=1234, print_bool=PRINT_BOOL)\n",
    "# Set which runner you want to use\n",
    "RUNNER = baseline_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f002e53",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mrun_gsm8k_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRUNNER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCURRENT_FILE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRESUME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mid_salt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCURRENT_ID_SALT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# optional but nice to set (dataset name/split/version)\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# NEW: continue after per-item failures\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_bool\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPRINT_BOOL\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mrun_gsm8k_batch\u001b[39m\u001b[34m(examples, runner, out_path, save_every, resume, id_salt, skip_errors, save_error_records, include_traceback, print_bool)\u001b[39m\n\u001b[32m     38\u001b[39m best = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# so the except block is safe\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     extra = \u001b[43mrunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgold_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     rec = {\n\u001b[32m     43\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: qid,\n\u001b[32m     44\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrow_index\u001b[39m\u001b[33m\"\u001b[39m: idx,\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m         **extra,\n\u001b[32m     50\u001b[39m     }\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mmake_baseline_runner.<locals>._runner\u001b[39m\u001b[34m(question, gold_num)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(prompt)\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-----\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m raw = \u001b[43mquery_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFINAL_SCHEMA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# your query_fn can ignore fmt for local gpt-oss\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m print_bool:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRaw model output:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mquery_fn_no_format_for_gptoss\u001b[39m\u001b[34m(prompt, model, fmt, seed)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m GPT_OSS_LOCAL_BUGGY_MODELS:\n\u001b[32m      6\u001b[39m     fmt = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQUERY_FN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/evoproc_procedures/ollama.py:83\u001b[39m, in \u001b[36mquery\u001b[39m\u001b[34m(prompt, model, fmt, seed)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquery\u001b[39m(\n\u001b[32m     64\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m     65\u001b[39m     model: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m     66\u001b[39m     fmt: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     67\u001b[39m     seed: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[32m1234\u001b[39m,\n\u001b[32m     68\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     69\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"General-purpose Ollama call.\u001b[39;00m\n\u001b[32m     70\u001b[39m \n\u001b[32m     71\u001b[39m \u001b[33;03m    This is your default structured call. When `fmt` is supplied, Ollama\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     81\u001b[39m \u001b[33;03m        Raw string response (often JSON text when `fmt` is provided).\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     res = \u001b[43mollama\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/ollama/_client.py:262\u001b[39m, in \u001b[36mClient.generate\u001b[39m\u001b[34m(self, model, prompt, suffix, system, template, context, stream, think, logprobs, top_logprobs, raw, format, images, options, keep_alive)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate\u001b[39m(\n\u001b[32m    234\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    235\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    250\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    251\u001b[39m ) -> Union[GenerateResponse, Iterator[GenerateResponse]]:\n\u001b[32m    252\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[33;03m  Create a response using the requested model.\u001b[39;00m\n\u001b[32m    254\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    259\u001b[39m \u001b[33;03m  Returns `GenerateResponse` if `stream` is `False`, otherwise returns a `GenerateResponse` generator.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mGenerateResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/generate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGenerateRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m      \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m      \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m      \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m      \u001b[49m\u001b[43mthink\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m      \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m      \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m      \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/ollama/_client.py:189\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    187\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/ollama/_client.py:129\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    128\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m     r.raise_for_status()\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/httpx/_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results = run_gsm8k_batch(\n",
    "    train_dataset, \n",
    "    runner=RUNNER,\n",
    "    out_path=CURRENT_FILE_PATH, \n",
    "    save_every=5,\n",
    "    resume=RESUME,\n",
    "    id_salt=CURRENT_ID_SALT,   # optional but nice to set (dataset name/split/version)\n",
    "    skip_errors=True,          # NEW: continue after per-item failures\n",
    "    print_bool=PRINT_BOOL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91259320",
   "metadata": {},
   "source": [
    "## ðŸŸ§ **Step 5**: Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa14e2d2",
   "metadata": {},
   "source": [
    "Read your results from your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa111236",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_results = None\n",
    "with open(CURRENT_FILE_PATH, \"r\") as f:\n",
    "    procs = [json.loads(line) for line in f]\n",
    "    read_results = procs\n",
    "    f.close()\n",
    "results_df = pd.DataFrame(read_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be118d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correct\n",
       "False    32\n",
       "True     17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(results_df[\"correct\"].value_counts())\n",
    "results_df[\"correct\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c6cc04",
   "metadata": {},
   "source": [
    "Printing to further investigate false answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeff996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\n",
      "Gold Answer: In the beginning, Betty has only 100 / 2 = $<<100/2=50>>50.\n",
      "Betty's grandparents gave her 15 * 2 = $<<15*2=30>>30.\n",
      "This means, Betty needs 100 - 50 - 30 - 15 = $<<100-50-30-15=5>>5 more.\n",
      "#### 5\n",
      "Predicted Answer: Betty needs $30 more to buy the wallet.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate how much more money Betty needs. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem text from the input.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - problem_text: The problem description.\n",
      "\n",
      "Step 2: Calculate the amount Betty has.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - money_she_has: The amount of money Betty has.\n",
      "\n",
      "Step 3: Calculate the amount Betty needs.\n",
      "  **Inputs**:\n",
      "    - money_she_has: The amount of money Betty has.\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - money_she_needs: The amount of money Betty needs.\n",
      "\n",
      "Step 4: Calculate how much more money Betty needs.\n",
      "  **Inputs**:\n",
      "    - money_she_needs: The amount of money Betty needs.\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - final_answer: The final answer.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\n",
      "Gold Answer: Maila read 12 x 2 = <<12*2=24>>24 pages today.\n",
      "So she was able to read a total of 12 + 24 = <<12+24=36>>36 pages since yesterday.\n",
      "There are 120 - 36 = <<120-36=84>>84 pages left to be read.\n",
      "Since she wants to read half of the remaining pages tomorrow, then she should read 84/2 = <<84/2=42>>42 pages.\n",
      "#### 42\n",
      "Predicted Answer: Julie will read 120 pages tomorrow.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate the number of pages Julie will read tomorrow. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the total number of pages in the book from the problem text.\n",
      "  **Inputs**:\n",
      "    - problem_text: The text of the problem.\n",
      "  **Outputs**:\n",
      "    - total_pages: The total number of pages in the book.\n",
      "\n",
      "Step 2: Calculate the number of pages read yesterday.\n",
      "  **Inputs**:\n",
      "    - total_pages: The total number of pages in the book.\n",
      "  **Outputs**:\n",
      "    - yesterdays_pages: The number of pages read yesterday.\n",
      "\n",
      "Step 3: Calculate the number of pages read today.\n",
      "  **Inputs**:\n",
      "    - total_pages: The total number of pages in the book.\n",
      "    - yesterdays_pages: The number of pages read yesterday.\n",
      "  **Outputs**:\n",
      "    - todays_pages: The number of pages read today.\n",
      "\n",
      "Step 4: Calculate the number of pages Julie will read tomorrow.\n",
      "  **Inputs**:\n",
      "    - todays_pages: The number of pages read today.\n",
      "    - yesterdays_pages: The number of pages read yesterday.\n",
      "  **Outputs**:\n",
      "    - tomorrows_pages: The number of pages Julie will read tomorrow.\n",
      "\n",
      "Step 5: Determine the number of pages Julie will read tomorrow.\n",
      "  **Inputs**:\n",
      "    - tomorrows_pages: The number of pages Julie will read tomorrow.\n",
      "  **Outputs**:\n",
      "    - final_answer: The final answer.\n",
      "\n",
      "---\n",
      "\n",
      "Question: James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\n",
      "Gold Answer: He writes each friend 3*2=<<3*2=6>>6 pages a week\n",
      "So he writes 6*2=<<6*2=12>>12 pages every week\n",
      "That means he writes 12*52=<<12*52=624>>624 pages a year\n",
      "#### 624\n",
      "Predicted Answer: The final answer is 104.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate the total pages James writes in a year. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem description from the input variable.\n",
      "  **Inputs**:\n",
      "    - problem_text: Input variable containing the problem description.\n",
      "  **Outputs**:\n",
      "    - problem_description: The extracted problem description.\n",
      "\n",
      "Step 2: Calculate the number of letters James writes per week.\n",
      "  **Inputs**:\n",
      "    - problem_description: Problem description containing the letter writing details.\n",
      "  **Outputs**:\n",
      "    - letters_per_week: The number of letters James writes per week.\n",
      "\n",
      "Step 3: Calculate the number of pages James writes per week.\n",
      "  **Inputs**:\n",
      "    - letters_per_week: The number of letters James writes per week.\n",
      "  **Outputs**:\n",
      "    - pages_per_week: The number of pages James writes per week.\n",
      "\n",
      "Step 4: Calculate the number of pages James writes per year.\n",
      "  **Inputs**:\n",
      "    - pages_per_week: The number of pages James writes per week.\n",
      "  **Outputs**:\n",
      "    - pages_per_year: The total number of pages James writes per year.\n",
      "\n",
      "Step 5: Output the final answer.\n",
      "  **Inputs**:\n",
      "    - pages_per_year: The total number of pages James writes per year.\n",
      "  **Outputs**:\n",
      "    - final_answer: The final answer: the total number of pages James writes in a year.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?\n",
      "Gold Answer: There are 80/100 * 10 = <<80/100*10=8>>8 more purple flowers than yellow flowers.\n",
      "So in Mark's garden, there are 10 + 8 = <<10+8=18>>18 purple flowers.\n",
      "Purple and yellow flowers sum up to 10 + 18 = <<10+18=28>>28 flowers.\n",
      "That means in Mark's garden there are 25/100 * 28 = <<25/100*28=7>>7 green flowers.\n",
      "So in total Mark has 28 + 7 = <<28+7=35>>35 plants in his garden.\n",
      "#### 35\n",
      "Predicted Answer: The total number of flowers is 140 + 60 = 200.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate the total number of flowers in the garden. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem text from the input.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem description\n",
      "  **Outputs**:\n",
      "    - problem_text: The problem text\n",
      "\n",
      "Step 2: Calculate the number of purple flowers.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text\n",
      "  **Outputs**:\n",
      "    - purple_flowers: The number of purple flowers\n",
      "\n",
      "Step 3: Calculate 80% more than the number of yellow flowers.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text\n",
      "    - purple_flowers: The number of purple flowers\n",
      "  **Outputs**:\n",
      "    - yellow_plus_80: The number of yellow flowers plus 80% more\n",
      "\n",
      "Step 4: Calculate the number of green flowers.\n",
      "  **Inputs**:\n",
      "    - yellow_plus_80: The number of yellow flowers plus 80% more\n",
      "    - purple_flowers: The number of purple flowers\n",
      "  **Outputs**:\n",
      "    - green_flowers: The number of green flowers\n",
      "\n",
      "Step 5: Calculate the total number of flowers.\n",
      "  **Inputs**:\n",
      "    - yellow_plus_80: The number of yellow flowers plus 80% more\n",
      "    - purple_flowers: The number of purple flowers\n",
      "    - green_flowers: The number of green flowers\n",
      "  **Outputs**:\n",
      "    - final_answer: The total number of flowers in the garden\n",
      "\n",
      "---\n",
      "\n",
      "Question: Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\n",
      "Gold Answer: He eats 32 from the largest pizzas because 2 x 16 = <<2*16=32>>32\n",
      "He eats 16 from the small pizza because 2 x 8 = <<2*8=16>>16\n",
      "He eats 48 pieces because 32 + 16 = <<32+16=48>>48\n",
      "#### 48\n",
      "Predicted Answer: The final number of slices is 34.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate the total number of pizza slices. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem text from the global state.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - problem_text: The extracted problem text.\n",
      "\n",
      "Step 2: Calculate the total number of slices from large pizzas.\n",
      "  **Inputs**:\n",
      "    - problem_text: The extracted problem text.\n",
      "  **Outputs**:\n",
      "    - slices_from_large: Number of slices from large pizzas.\n",
      "\n",
      "Step 3: Calculate the total number of slices from small pizzas.\n",
      "  **Inputs**:\n",
      "    - problem_text: The extracted problem text.\n",
      "  **Outputs**:\n",
      "    - slices_from_small: Number of slices from small pizzas.\n",
      "\n",
      "Step 4: Calculate the total number of slices.\n",
      "  **Inputs**:\n",
      "    - slices_from_large: Number of slices from large pizzas.\n",
      "    - slices_from_small: Number of slices from small pizzas.\n",
      "  **Outputs**:\n",
      "    - total_slices: The total number of pizza slices.\n",
      "\n",
      "Step 5: Output the final answer.\n",
      "  **Inputs**:\n",
      "    - total_slices: The total number of pizza slices.\n",
      "  **Outputs**:\n",
      "    - final_answer: The final answer in a descriptive form.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Alexis is applying for a new job and bought a new set of business clothes to wear to the interview. She went to a department store with a budget of $200 and spent $30 on a button-up shirt, $46 on suit pants, $38 on a suit coat, $11 on socks, and $18 on a belt. She also purchased a pair of shoes, but lost the receipt for them. She has $16 left from her budget. How much did Alexis pay for the shoes?\n",
      "Gold Answer: Let S be the amount Alexis paid for the shoes.\n",
      "She spent S + 30 + 46 + 38 + 11 + 18 = S + <<+30+46+38+11+18=143>>143.\n",
      "She used all but $16 of her budget, so S + 143 = 200 - 16 = 184.\n",
      "Thus, Alexis paid S = 184 - 143 = $<<184-143=41>>41 for the shoes.\n",
      "#### 41\n",
      "Predicted Answer: The amount spent on the shoes is $89.99.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate the cost of the shoes. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem text from the input.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text to be processed.\n",
      "  **Outputs**:\n",
      "\n",
      "Step 2: Calculate the total cost of the other items.\n",
      "  **Inputs**:\n",
      "  **Outputs**:\n",
      "\n",
      "Step 3: Calculate the amount spent on the shoes.\n",
      "  **Inputs**:\n",
      "  **Outputs**:\n",
      "    - final_answer: The final answer to the problem.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\n",
      "Gold Answer: She works 8 hours a day for $18 per hour so she makes 8*18 = $<<8*18=144.00>>144.00 per 8-hour shift\n",
      "She works 10 hours a day and anything over 8 hours is eligible for overtime, so she gets 10-8 = <<10-8=2>>2 hours of overtime\n",
      "Overtime is calculated as time and a half so and she makes $18/hour so her overtime pay is 18*.5 = $<<18*.5=9.00>>9.00\n",
      "Her overtime pay is 18+9 = $<<18+9=27.00>>27.00\n",
      "Her base pay is $144.00 per 8-hour shift and she works 5 days and makes 5 * $144 = $<<144*5=720.00>>720.00\n",
      "Her overtime pay is $27.00 per hour and she works 2 hours of overtime per day and makes 27*2 = $<<27*2=54.00>>54.00 in overtime pay\n",
      "2 hours of overtime pay for 5 days means she makes 54*5 = $270.00\n",
      "In 5 days her base pay is $720.00 and she makes $270.00 in overtime pay so she makes $720 + $270 = $<<720+270=990.00>>990.00\n",
      "#### 990\n",
      "Predicted Answer: Tina makes $2250.00.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate Tina's total earnings. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem text from the input.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - problem_text: The problem text.\n",
      "\n",
      "Step 2: Calculate the regular earnings for 5 days at 10 hours per day.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text.\n",
      "  **Outputs**:\n",
      "    - total_hours: Total hours worked.\n",
      "\n",
      "Step 3: Calculate the overtime hours. Overtime is paid for hours worked over 8.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text.\n",
      "    - total_hours: Total hours worked.\n",
      "  **Outputs**:\n",
      "    - overtime_hours: Hours worked in overtime.\n",
      "\n",
      "Step 4: Calculate the overtime rate.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text.\n",
      "    - total_hours: Total hours worked.\n",
      "    - overtime_hours: Hours worked in overtime.\n",
      "  **Outputs**:\n",
      "    - overtime_rate: Overtime rate.\n",
      "\n",
      "Step 5: Calculate the total earnings.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text.\n",
      "    - total_hours: Total hours worked.\n",
      "    - overtime_rate: Overtime rate.\n",
      "  **Outputs**:\n",
      "    - final_answer: The final earnings calculation.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "false_answers = results_df[results_df[\"correct\"]==False]\n",
    "for index, row in false_answers.iterrows():\n",
    "    print(f\"Question: {row['question']}\")\n",
    "    print(f\"Gold Answer: {row['gold_answer']}\")\n",
    "    print(f\"Predicted Answer: {row['pred_answer']}\")\n",
    "    print(\"Procedure:\")\n",
    "    pretty_print(row['procedure'])\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f57f1d",
   "metadata": {},
   "source": [
    "Looking at an isolated false answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d097c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 1] inputs: {'problem_text': 'Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?'}\n",
      "[step 1] outputs: {k: state[k] for k in ['total_pages'] if k in state}\n",
      "[step 2] inputs: {'total_pages': 120}\n",
      "[step 2] outputs: {k: state[k] for k in ['yesterdays_pages'] if k in state}\n",
      "[step 3] inputs: {'total_pages': 120, 'yesterdays_pages': 0}\n",
      "[step 3] outputs: {k: state[k] for k in ['todays_pages'] if k in state}\n",
      "[step 4] inputs: {'todays_pages': 120, 'yesterdays_pages': 0}\n",
      "[step 4] outputs: {k: state[k] for k in ['tomorrows_pages'] if k in state}\n",
      "[step 5] inputs: {'tomorrows_pages': 120}\n",
      "[step 5] outputs: {k: state[k] for k in ['final_answer', 'final_answer_numerical', 'confidence', 'units'] if k in state}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'problem_text': 'Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?',\n",
       " 'total_pages': 120,\n",
       " 'yesterdays_pages': 0,\n",
       " 'todays_pages': 120,\n",
       " 'tomorrows_pages': 120,\n",
       " 'final_answer': 'Julie will read 120 pages tomorrow.',\n",
       " 'final_answer_numerical': 120,\n",
       " 'confidence': 1,\n",
       " 'units': 'pages'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this = false_answers.iloc[1]\n",
    "run_steps_stateful_minimal(this['procedure'], this['question'], FINAL_SCHEMA, ga.model, print_bool=True, query_fn=QUERY_FN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
