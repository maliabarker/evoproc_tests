{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e350c961",
   "metadata": {},
   "source": [
    "# Research Example: Generating evoproc_procedures for the GSM8K Dataset Using a Genetic Algorithm and OLLaMa Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ad3473",
   "metadata": {},
   "source": [
    "## Step 1: Import packages and necessary application functions & variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08cc3cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "from hashlib import blake2b\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from evoproc.ga_scaffold_structured import ProcedureGA, GAConfig\n",
    "from evoproc.validators import validate_procedure_structured\n",
    "from evoproc_procedures.models import Procedure\n",
    "from evoproc_procedures.schemas import get_schema\n",
    "from evoproc_procedures.prompts import create_procedure_prompt\n",
    "from evoproc_procedures.ollama import query, repair_fn_ollama\n",
    "from evoproc_procedures.runners import run_steps_stateful_minimal\n",
    "from evoproc_procedures.helpers import pretty_print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afda795",
   "metadata": {},
   "source": [
    "## Step 2: Import the GSM8K Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661e6381",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"openai/gsm8k\", \"main\", split=\"train\")\n",
    "test_dataset = load_dataset(\"openai/gsm8k\", \"main\", split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf261a71",
   "metadata": {},
   "source": [
    "## Step 3: Set variable constants and instantiate necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d6ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_SCHEMA = get_schema(\"gsm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2beac706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_steps_fn(proc_json, question, final_answer_schema, model, print_bool=False):\n",
    "    # use your general runner (backend-agnostic; pass Ollama query fn)\n",
    "    state = run_steps_stateful_minimal(\n",
    "        proc_json,\n",
    "        problem_text=question,\n",
    "        answer_schema=final_answer_schema,\n",
    "        model=model,\n",
    "        query_fn=query,\n",
    "        print_bool=print_bool,\n",
    "    )\n",
    "    return state\n",
    "\n",
    "def _extract_gold_number(gold_answer: str) -> float | None:\n",
    "    # GSM8K gold answers are strings; often last number is the target\n",
    "    nums = re.findall(r\"-?\\d+(?:\\.\\d+)?\", gold_answer)\n",
    "    return float(nums[-1]) if nums else None\n",
    "\n",
    "def eval_fn(state, proc_json) -> float:\n",
    "    \"\"\"Return a fitness score in [0,1].\"\"\"\n",
    "    # prefer model-extracted numeric if present, else try to parse its text\n",
    "    pred_num = state.get(\"final_answer_numerical\")\n",
    "    if pred_num is None:\n",
    "        try:\n",
    "            pred_num = float(re.findall(r\"-?\\d+(?:\\.\\d+)?\", state.get(\"final_answer\",\"\"))[-1])\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    gold_num = state.get(\"_gold_num\")  # weâ€™ll inject this per item\n",
    "    if gold_num is None:\n",
    "        return 0.0\n",
    "    # exact match or close within small tolerance\n",
    "    return 1.0 if math.isclose(pred_num, gold_num, rel_tol=0, abs_tol=1e-6) else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c78fa",
   "metadata": {},
   "source": [
    "## Step 3: Instantiate the Procedure Genetic Algorithm Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee1f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = ProcedureGA(\n",
    "    model=\"gemma3:latest\",\n",
    "    create_proc_fn=lambda task: create_procedure_prompt(task),\n",
    "    query_fn=query,                                     # backend call\n",
    "    schema_json_fn=lambda: Procedure.model_json_schema(),\n",
    "    validate_fn=validate_procedure_structured,          # pure function\n",
    "    repair_fn=repair_fn_ollama,                         # GA expects (proc, model) -> proc\n",
    "    cfg=GAConfig(population_size=3, max_generations=3, crossover_rate=0.5, mutation_rate=0.5, seed=42),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e71602",
   "metadata": {},
   "source": [
    "## Step 4: For each Question-Answer pair, run the GA with the question as task_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9387611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _append_jsonl(path, items):\n",
    "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        for it in items:\n",
    "            f.write(json.dumps(it, ensure_ascii=False) + \"\\n\")\n",
    "        f.flush()\n",
    "        os.fsync(f.fileno())\n",
    "\n",
    "def _load_existing_ids(path):\n",
    "    ids = set()\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                try:\n",
    "                    rec = json.loads(line)\n",
    "                    if \"id\" in rec and rec[\"id\"] is not None:\n",
    "                        ids.add(rec[\"id\"])\n",
    "                except json.JSONDecodeError:\n",
    "                    # tolerate a partially written last line\n",
    "                    continue\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    return ids\n",
    "\n",
    "def _stable_example_id(ex, *, salt=\"\"):\n",
    "    \"\"\"\n",
    "    Make a deterministic ID when dataset lacks 'id'.\n",
    "    Uses question+answer (+ optional salt) to avoid changing if order changes.\n",
    "    \"\"\"\n",
    "    # If a real id exists, reuse it\n",
    "    if ex.get(\"id\") is not None:\n",
    "        return str(ex[\"id\"])\n",
    "\n",
    "    q = (ex.get(\"question\") or \"\").strip()\n",
    "    a = (ex.get(\"answer\") or \"\").strip()\n",
    "    h = blake2b(digest_size=16)  # 128-bit\n",
    "    h.update(salt.encode(\"utf-8\", \"ignore\"))\n",
    "    h.update(q.encode(\"utf-8\", \"ignore\"))\n",
    "    h.update(b\"\\x1e\")  # delimiter\n",
    "    h.update(a.encode(\"utf-8\", \"ignore\"))\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _numbers_equal(a, b, tol=1e-9):\n",
    "    if a is None or b is None:\n",
    "        return False\n",
    "    try:\n",
    "        return abs(float(a) - float(b)) < tol\n",
    "    except Exception:\n",
    "        return a == b\n",
    "\n",
    "def run_gsm8k_batch(\n",
    "    examples,\n",
    "    out_path=None,          # e.g., \"runs/gsm8k_results.jsonl\"\n",
    "    save_every=10,          # write every N examples\n",
    "    resume=False,           # skip examples whose IDs are already in out_path\n",
    "    id_salt=\"\",             # optional: add dataset name/split/version here for extra uniqueness\n",
    "):\n",
    "    \"\"\"\n",
    "    examples: iterable of dicts like {\"question\": \"...\", \"answer\": \"...\"} (GSM8K format)\n",
    "    Returns: list of per-item result dicts with procedure, state, and score.\n",
    "    Persists results to JSONL every `save_every`. If `resume=True`, skips already-saved IDs.\n",
    "    \"\"\"\n",
    "    pending = []\n",
    "    results = []\n",
    "    existing_ids = _load_existing_ids(out_path) if (resume and out_path) else set()\n",
    "\n",
    "    wrote_on_exception = False\n",
    "    try:\n",
    "        for idx, ex in enumerate(examples):\n",
    "            qid = _stable_example_id(ex, salt=id_salt)\n",
    "            if resume and out_path and (qid in existing_ids):\n",
    "                continue\n",
    "\n",
    "            question = ex[\"question\"]\n",
    "            gold_text = ex[\"answer\"]\n",
    "            gold_num = _extract_gold_number(gold_text)\n",
    "\n",
    "            # ---- choose one path as before ----\n",
    "            # # 1) Task-eval during GA:\n",
    "            # best, history = ga.run(\n",
    "            #     task_description=question,\n",
    "            #     final_answer_schema=FINAL_SCHEMA,\n",
    "            #     eval_fn=lambda state, proc: eval_fn({**state, \"_gold_num\": gold_num}, proc),\n",
    "            #     run_steps_fn=run_steps_fn,\n",
    "            #     print_progress=False,\n",
    "            # )\n",
    "\n",
    "            # 2) Hygiene-only during GA:\n",
    "            best, history = ga.run(\n",
    "                task_description=question,\n",
    "                final_answer_schema=FINAL_SCHEMA,\n",
    "                eval_fn=None,\n",
    "                print_progress=False,\n",
    "            )\n",
    "\n",
    "            # Collect final state/answer\n",
    "            final_state = run_steps_fn(best.proc, question, FINAL_SCHEMA, ga.model, print_bool=False)\n",
    "\n",
    "            pred_ans = final_state.get(\"final_answer\")\n",
    "            pred_num = final_state.get(\"final_answer_numerical\")\n",
    "\n",
    "            # If you're not passing a real eval_fn, fall back to numeric equality.\n",
    "            if 'eval_fn' in globals() and callable(globals()['eval_fn']):\n",
    "                correct = bool(eval_fn({**final_state, \"_gold_num\": gold_num}, best.proc) >= 1.0)\n",
    "            else:\n",
    "                correct = _numbers_equal(pred_num, gold_num)\n",
    "\n",
    "            rec = {\n",
    "                \"id\": qid,                      # stable ID even without dataset-provided 'id'\n",
    "                \"row_index\": idx,               # helpful for debugging\n",
    "                \"question\": question,\n",
    "                \"gold_answer\": gold_text,\n",
    "                \"gold_num\": gold_num,\n",
    "                \"fitness\": best.fitness,\n",
    "                \"procedure\": best.proc,         # JSON dict\n",
    "                \"state\": final_state,           # includes final answer(s)\n",
    "                \"pred_answer\": pred_ans,\n",
    "                \"pred_num\": pred_num,\n",
    "                \"correct\": bool(correct),\n",
    "                \"steps\": len(best.proc.get(\"steps\", [])),\n",
    "            }\n",
    "\n",
    "            results.append(rec)\n",
    "            if out_path:\n",
    "                pending.append(rec)\n",
    "                if len(pending) >= save_every:\n",
    "                    _append_jsonl(out_path, pending)\n",
    "                    pending.clear()\n",
    "\n",
    "    except Exception:\n",
    "        if out_path and pending:\n",
    "            _append_jsonl(out_path, pending)\n",
    "            pending.clear()\n",
    "            wrote_on_exception = True\n",
    "        raise\n",
    "    finally:\n",
    "        if out_path and pending and not wrote_on_exception:\n",
    "            _append_jsonl(out_path, pending)\n",
    "            pending.clear()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "581ef386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing purposes, just grab first 10 as this will take a long time to run\n",
    "first_ten = train_dataset.select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d90871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run\n",
    "results = run_gsm8k_batch(\n",
    "    first_ten, \n",
    "    out_path=\"runs/gsm8k_train.jsonl\", \n",
    "    save_every=5, \n",
    "    resume=False,\n",
    "    id_salt=\"gsm8k-train-v1\"   # optional but nice to set (dataset name/split/version)\n",
    ")\n",
    "\n",
    "# Resume after an interruption\n",
    "# results = run_gsm8k_batch(\n",
    "#     first_ten, \n",
    "#     out_path=\"runs/gsm8k_train.jsonl\", \n",
    "#     save_every=10, \n",
    "#     resume=True,\n",
    "#     id_salt=\"gsm8k-train-v1\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa111236",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_results = None\n",
    "with open(\"runs/gsm8k_train.jsonl\", \"r\") as f:\n",
    "    procs = [json.loads(line) for line in f]\n",
    "    read_results = procs\n",
    "    f.close()\n",
    "first_ten_df = pd.DataFrame(read_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52c8bbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='correct'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_ten_df[\"correct\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eeff996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\n",
      "Gold Answer: In the beginning, Betty has only 100 / 2 = $<<100/2=50>>50.\n",
      "Betty's grandparents gave her 15 * 2 = $<<15*2=30>>30.\n",
      "This means, Betty needs 100 - 50 - 30 - 15 = $<<100-50-30-15=5>>5 more.\n",
      "#### 5\n",
      "Predicted Answer: Betty needs $30 more to buy the wallet.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate how much more money Betty needs. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem text from the input.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - problem_text: The problem description.\n",
      "\n",
      "Step 2: Calculate the amount Betty has.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - money_she_has: The amount of money Betty has.\n",
      "\n",
      "Step 3: Calculate the amount Betty needs.\n",
      "  **Inputs**:\n",
      "    - money_she_has: The amount of money Betty has.\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - money_she_needs: The amount of money Betty needs.\n",
      "\n",
      "Step 4: Calculate how much more money Betty needs.\n",
      "  **Inputs**:\n",
      "    - money_she_needs: The amount of money Betty needs.\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - final_answer: The final answer.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\n",
      "Gold Answer: Maila read 12 x 2 = <<12*2=24>>24 pages today.\n",
      "So she was able to read a total of 12 + 24 = <<12+24=36>>36 pages since yesterday.\n",
      "There are 120 - 36 = <<120-36=84>>84 pages left to be read.\n",
      "Since she wants to read half of the remaining pages tomorrow, then she should read 84/2 = <<84/2=42>>42 pages.\n",
      "#### 42\n",
      "Predicted Answer: Julie will read 120 pages tomorrow.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate the number of pages Julie will read tomorrow. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the total number of pages in the book from the problem text.\n",
      "  **Inputs**:\n",
      "    - problem_text: The text of the problem.\n",
      "  **Outputs**:\n",
      "    - total_pages: The total number of pages in the book.\n",
      "\n",
      "Step 2: Calculate the number of pages read yesterday.\n",
      "  **Inputs**:\n",
      "    - total_pages: The total number of pages in the book.\n",
      "  **Outputs**:\n",
      "    - yesterdays_pages: The number of pages read yesterday.\n",
      "\n",
      "Step 3: Calculate the number of pages read today.\n",
      "  **Inputs**:\n",
      "    - total_pages: The total number of pages in the book.\n",
      "    - yesterdays_pages: The number of pages read yesterday.\n",
      "  **Outputs**:\n",
      "    - todays_pages: The number of pages read today.\n",
      "\n",
      "Step 4: Calculate the number of pages Julie will read tomorrow.\n",
      "  **Inputs**:\n",
      "    - todays_pages: The number of pages read today.\n",
      "    - yesterdays_pages: The number of pages read yesterday.\n",
      "  **Outputs**:\n",
      "    - tomorrows_pages: The number of pages Julie will read tomorrow.\n",
      "\n",
      "Step 5: Determine the number of pages Julie will read tomorrow.\n",
      "  **Inputs**:\n",
      "    - tomorrows_pages: The number of pages Julie will read tomorrow.\n",
      "  **Outputs**:\n",
      "    - final_answer: The final answer.\n",
      "\n",
      "---\n",
      "\n",
      "Question: James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\n",
      "Gold Answer: He writes each friend 3*2=<<3*2=6>>6 pages a week\n",
      "So he writes 6*2=<<6*2=12>>12 pages every week\n",
      "That means he writes 12*52=<<12*52=624>>624 pages a year\n",
      "#### 624\n",
      "Predicted Answer: The final answer is 104.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate the total pages James writes in a year. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem description from the input variable.\n",
      "  **Inputs**:\n",
      "    - problem_text: Input variable containing the problem description.\n",
      "  **Outputs**:\n",
      "    - problem_description: The extracted problem description.\n",
      "\n",
      "Step 2: Calculate the number of letters James writes per week.\n",
      "  **Inputs**:\n",
      "    - problem_description: Problem description containing the letter writing details.\n",
      "  **Outputs**:\n",
      "    - letters_per_week: The number of letters James writes per week.\n",
      "\n",
      "Step 3: Calculate the number of pages James writes per week.\n",
      "  **Inputs**:\n",
      "    - letters_per_week: The number of letters James writes per week.\n",
      "  **Outputs**:\n",
      "    - pages_per_week: The number of pages James writes per week.\n",
      "\n",
      "Step 4: Calculate the number of pages James writes per year.\n",
      "  **Inputs**:\n",
      "    - pages_per_week: The number of pages James writes per week.\n",
      "  **Outputs**:\n",
      "    - pages_per_year: The total number of pages James writes per year.\n",
      "\n",
      "Step 5: Output the final answer.\n",
      "  **Inputs**:\n",
      "    - pages_per_year: The total number of pages James writes per year.\n",
      "  **Outputs**:\n",
      "    - final_answer: The final answer: the total number of pages James writes in a year.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?\n",
      "Gold Answer: There are 80/100 * 10 = <<80/100*10=8>>8 more purple flowers than yellow flowers.\n",
      "So in Mark's garden, there are 10 + 8 = <<10+8=18>>18 purple flowers.\n",
      "Purple and yellow flowers sum up to 10 + 18 = <<10+18=28>>28 flowers.\n",
      "That means in Mark's garden there are 25/100 * 28 = <<25/100*28=7>>7 green flowers.\n",
      "So in total Mark has 28 + 7 = <<28+7=35>>35 plants in his garden.\n",
      "#### 35\n",
      "Predicted Answer: The total number of flowers is 140 + 60 = 200.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate the total number of flowers in the garden. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem text from the input.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem description\n",
      "  **Outputs**:\n",
      "    - problem_text: The problem text\n",
      "\n",
      "Step 2: Calculate the number of purple flowers.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text\n",
      "  **Outputs**:\n",
      "    - purple_flowers: The number of purple flowers\n",
      "\n",
      "Step 3: Calculate 80% more than the number of yellow flowers.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text\n",
      "    - purple_flowers: The number of purple flowers\n",
      "  **Outputs**:\n",
      "    - yellow_plus_80: The number of yellow flowers plus 80% more\n",
      "\n",
      "Step 4: Calculate the number of green flowers.\n",
      "  **Inputs**:\n",
      "    - yellow_plus_80: The number of yellow flowers plus 80% more\n",
      "    - purple_flowers: The number of purple flowers\n",
      "  **Outputs**:\n",
      "    - green_flowers: The number of green flowers\n",
      "\n",
      "Step 5: Calculate the total number of flowers.\n",
      "  **Inputs**:\n",
      "    - yellow_plus_80: The number of yellow flowers plus 80% more\n",
      "    - purple_flowers: The number of purple flowers\n",
      "    - green_flowers: The number of green flowers\n",
      "  **Outputs**:\n",
      "    - final_answer: The total number of flowers in the garden\n",
      "\n",
      "---\n",
      "\n",
      "Question: Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\n",
      "Gold Answer: He eats 32 from the largest pizzas because 2 x 16 = <<2*16=32>>32\n",
      "He eats 16 from the small pizza because 2 x 8 = <<2*8=16>>16\n",
      "He eats 48 pieces because 32 + 16 = <<32+16=48>>48\n",
      "#### 48\n",
      "Predicted Answer: The final number of slices is 34.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate the total number of pizza slices. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem text from the global state.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - problem_text: The extracted problem text.\n",
      "\n",
      "Step 2: Calculate the total number of slices from large pizzas.\n",
      "  **Inputs**:\n",
      "    - problem_text: The extracted problem text.\n",
      "  **Outputs**:\n",
      "    - slices_from_large: Number of slices from large pizzas.\n",
      "\n",
      "Step 3: Calculate the total number of slices from small pizzas.\n",
      "  **Inputs**:\n",
      "    - problem_text: The extracted problem text.\n",
      "  **Outputs**:\n",
      "    - slices_from_small: Number of slices from small pizzas.\n",
      "\n",
      "Step 4: Calculate the total number of slices.\n",
      "  **Inputs**:\n",
      "    - slices_from_large: Number of slices from large pizzas.\n",
      "    - slices_from_small: Number of slices from small pizzas.\n",
      "  **Outputs**:\n",
      "    - total_slices: The total number of pizza slices.\n",
      "\n",
      "Step 5: Output the final answer.\n",
      "  **Inputs**:\n",
      "    - total_slices: The total number of pizza slices.\n",
      "  **Outputs**:\n",
      "    - final_answer: The final answer in a descriptive form.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Alexis is applying for a new job and bought a new set of business clothes to wear to the interview. She went to a department store with a budget of $200 and spent $30 on a button-up shirt, $46 on suit pants, $38 on a suit coat, $11 on socks, and $18 on a belt. She also purchased a pair of shoes, but lost the receipt for them. She has $16 left from her budget. How much did Alexis pay for the shoes?\n",
      "Gold Answer: Let S be the amount Alexis paid for the shoes.\n",
      "She spent S + 30 + 46 + 38 + 11 + 18 = S + <<+30+46+38+11+18=143>>143.\n",
      "She used all but $16 of her budget, so S + 143 = 200 - 16 = 184.\n",
      "Thus, Alexis paid S = 184 - 143 = $<<184-143=41>>41 for the shoes.\n",
      "#### 41\n",
      "Predicted Answer: The amount spent on the shoes is $89.99.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate the cost of the shoes. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem text from the input.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text to be processed.\n",
      "  **Outputs**:\n",
      "\n",
      "Step 2: Calculate the total cost of the other items.\n",
      "  **Inputs**:\n",
      "  **Outputs**:\n",
      "\n",
      "Step 3: Calculate the amount spent on the shoes.\n",
      "  **Inputs**:\n",
      "  **Outputs**:\n",
      "    - final_answer: The final answer to the problem.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\n",
      "Gold Answer: She works 8 hours a day for $18 per hour so she makes 8*18 = $<<8*18=144.00>>144.00 per 8-hour shift\n",
      "She works 10 hours a day and anything over 8 hours is eligible for overtime, so she gets 10-8 = <<10-8=2>>2 hours of overtime\n",
      "Overtime is calculated as time and a half so and she makes $18/hour so her overtime pay is 18*.5 = $<<18*.5=9.00>>9.00\n",
      "Her overtime pay is 18+9 = $<<18+9=27.00>>27.00\n",
      "Her base pay is $144.00 per 8-hour shift and she works 5 days and makes 5 * $144 = $<<144*5=720.00>>720.00\n",
      "Her overtime pay is $27.00 per hour and she works 2 hours of overtime per day and makes 27*2 = $<<27*2=54.00>>54.00 in overtime pay\n",
      "2 hours of overtime pay for 5 days means she makes 54*5 = $270.00\n",
      "In 5 days her base pay is $720.00 and she makes $270.00 in overtime pay so she makes $720 + $270 = $<<720+270=990.00>>990.00\n",
      "#### 990\n",
      "Predicted Answer: Tina makes $2250.00.\n",
      "Procedure:\n",
      "\n",
      "--- Procedure: Calculate Tina's total earnings. ---\n",
      "Steps:\n",
      "\n",
      "Step 1: Extract the problem text from the input.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem description.\n",
      "  **Outputs**:\n",
      "    - problem_text: The problem text.\n",
      "\n",
      "Step 2: Calculate the regular earnings for 5 days at 10 hours per day.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text.\n",
      "  **Outputs**:\n",
      "    - total_hours: Total hours worked.\n",
      "\n",
      "Step 3: Calculate the overtime hours. Overtime is paid for hours worked over 8.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text.\n",
      "    - total_hours: Total hours worked.\n",
      "  **Outputs**:\n",
      "    - overtime_hours: Hours worked in overtime.\n",
      "\n",
      "Step 4: Calculate the overtime rate.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text.\n",
      "    - total_hours: Total hours worked.\n",
      "    - overtime_hours: Hours worked in overtime.\n",
      "  **Outputs**:\n",
      "    - overtime_rate: Overtime rate.\n",
      "\n",
      "Step 5: Calculate the total earnings.\n",
      "  **Inputs**:\n",
      "    - problem_text: The problem text.\n",
      "    - total_hours: Total hours worked.\n",
      "    - overtime_rate: Overtime rate.\n",
      "  **Outputs**:\n",
      "    - final_answer: The final earnings calculation.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "false_answers = first_ten_df[first_ten_df[\"correct\"]==False]\n",
    "for index, row in false_answers.iterrows():\n",
    "    print(f\"Question: {row['question']}\")\n",
    "    print(f\"Gold Answer: {row['gold_answer']}\")\n",
    "    print(f\"Predicted Answer: {row['pred_answer']}\")\n",
    "    print(\"Procedure:\")\n",
    "    pretty_print(row['procedure'])\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91d097c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step 1] inputs: {'problem_text': 'Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?'}\n",
      "[step 1] outputs: {k: state[k] for k in ['total_pages'] if k in state}\n",
      "[step 2] inputs: {'total_pages': 120}\n",
      "[step 2] outputs: {k: state[k] for k in ['yesterdays_pages'] if k in state}\n",
      "[step 3] inputs: {'total_pages': 120, 'yesterdays_pages': 0}\n",
      "[step 3] outputs: {k: state[k] for k in ['todays_pages'] if k in state}\n",
      "[step 4] inputs: {'todays_pages': 120, 'yesterdays_pages': 0}\n",
      "[step 4] outputs: {k: state[k] for k in ['tomorrows_pages'] if k in state}\n",
      "[step 5] inputs: {'tomorrows_pages': 120}\n",
      "[step 5] outputs: {k: state[k] for k in ['final_answer', 'final_answer_numerical', 'confidence', 'units'] if k in state}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'problem_text': 'Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?',\n",
       " 'total_pages': 120,\n",
       " 'yesterdays_pages': 0,\n",
       " 'todays_pages': 120,\n",
       " 'tomorrows_pages': 120,\n",
       " 'final_answer': 'Julie will read 120 pages tomorrow.',\n",
       " 'final_answer_numerical': 120,\n",
       " 'confidence': 1,\n",
       " 'units': 'pages'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this = false_answers.iloc[1]\n",
    "run_steps_fn(this['procedure'], this['question'], FINAL_SCHEMA, ga.model, print_bool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6138a85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    5ea421376648e9dd79cfbe0795691974\n",
       "3    005bd9af151fa2a421d68bcab4a65f6b\n",
       "4    46b52aae613b035a1aef1839a66a52f5\n",
       "5    ac583ea43a6c74d49182df23d5c37828\n",
       "6    ae555952684315fa7fe869f1b5c76115\n",
       "8    35961f7131976b98f45a267c8b1b8f78\n",
       "9    7a2ff0ffda6b1eebf1d6ce8ece6d2bbd\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_answers[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4a604dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open(\"runs/gsm8k_train.jsonl\", \"r\") as f:\n",
    "#     procs = [json.loads(line) for line in f]\n",
    "#     for proc in procs:\n",
    "#         txt = f\"\"\"\n",
    "#                 Question: {proc['question']}\n",
    "#                 Gold Answer: {proc['gold_answer']}\n",
    "#                 Predicted Answer: {proc['pred_answer']}\n",
    "#                 Correct: {proc['correct']}\n",
    "#                 Fitness: {proc['fitness']}\n",
    "#                 Steps: {proc['steps']}\n",
    "#                 Procedure: {pretty_print(proc['procedure'])}\n",
    "#                 \"\"\"\n",
    "#         print(txt)\n",
    "#         print(\"\\n\")\n",
    "#     f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d728104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
